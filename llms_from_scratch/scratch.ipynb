{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 101,
         "metadata": {},
         "outputs": [],
         "source": [
            "import tiktoken\n",
            "import re"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 102,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "20479\n"
               ]
            }
         ],
         "source": [
            "with open(\"the-verdict.txt\", \"r\") as f:\n",
            "    lines = f.read()\n",
            "\n",
            "print(len(lines))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 103,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ']\n",
                  "4690\n"
               ]
            }
         ],
         "source": [
            "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', lines)\n",
            "print(preprocessed[:10])\n",
            "preprocessed = [item for item in preprocessed if item.strip()]\n",
            "print(len(preprocessed))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 104,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['would', 'wouldn', 'year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself']\n",
                  "1130\n",
                  "! 0\n",
                  "\" 1\n",
                  "' 2\n",
                  "( 3\n",
                  ") 4\n",
                  ", 5\n",
                  "-- 6\n",
                  ". 7\n",
                  ": 8\n",
                  "; 9\n",
                  "? 10\n"
               ]
            }
         ],
         "source": [
            "all_words = sorted(set(preprocessed))\n",
            "print(all_words[-10:])\n",
            "vocab_size = len(all_words)\n",
            "print(vocab_size)\n",
            "vocab = {token: idx for idx, token in enumerate(all_words)}\n",
            "for i, word in enumerate(vocab):\n",
            "    if i > 10:\n",
            "        break\n",
            "    print(word, vocab[word])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 105,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[989, 1077, 7, 7]\n",
                  "their was..\n"
               ]
            }
         ],
         "source": [
            "class SimpleTokenizerV1:\n",
            "    def __init__(self, vocab):\n",
            "        self.token_to_int = vocab\n",
            "        self.int_to_token = {idx: token for token, idx in vocab.items()}\n",
            "    \n",
            "    def encode(self, text):\n",
            "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
            "        preprocessed = [item for item in preprocessed if item.strip()]\n",
            "        return [self.token_to_int[token] for token in preprocessed]\n",
            "    \n",
            "    def decode(self, integers):\n",
            "        text = \" \".join([self.int_to_token[idx] for idx in integers])\n",
            "        # replaces spaces before punctuation marks for format sentences correctly\n",
            "        text = re.sub(r'\\s+([,.:;?_!\"()\\'])', r'\\1', text)\n",
            "        return text\n",
            "    \n",
            "tokenizer = SimpleTokenizerV1(vocab)\n",
            "test = \"their  was..\"\n",
            "print(tokenizer.encode(test))\n",
            "print(tokenizer.decode(tokenizer.encode(test)))\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 106,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "('younger', 1127)\n",
                  "('your', 1128)\n",
                  "('yourself', 1129)\n",
                  "('<|unk|>', 1130)\n",
                  "('<|endoftext|>', 1131)\n",
                  "Hi, do you like tea? <|endoftext|> In the sunlit terraces\n"
               ]
            }
         ],
         "source": [
            "all_words.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
            "all_words\n",
            "vocab = {token: idx for idx, token in enumerate(all_words)}\n",
            "max = 10\n",
            "for i, item in enumerate(list(vocab.items())[-5:]):\n",
            "    if i > max:\n",
            "        break\n",
            "    print(item)\n",
            "text1 = \"Hi, do you like tea?\"\n",
            "text2 = \"In the sunlit terraces\"\n",
            "text = \" <|endoftext|> \".join((text1, text2))\n",
            "\n",
            "print(text)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 107,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[1130, 5, 355, 1126, 628, 975, 10, 1131, 55, 988, 956, 984]\n",
                  "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces\n",
                  "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces\n"
               ]
            }
         ],
         "source": [
            "class SimpleTokenizerV2:\n",
            "    def __init__(self, vocab):\n",
            "        self.token_to_int = vocab\n",
            "        self.int_to_token = {idx: token for  token, idx in vocab.items()}\n",
            "    \n",
            "    def encode(self, text):\n",
            "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
            "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
            "        preprocessed = [item if item in self.token_to_int else \"<|unk|>\" for item in preprocessed]\n",
            "        return [self.token_to_int[token] for token in preprocessed]\n",
            "\n",
            "    def decode(self, integers):\n",
            "        text = \" \".join([self.int_to_token[idx] for idx in integers])\n",
            "        # replaces spaces before punctuation marks for format sentences correctly\n",
            "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
            "        return text\n",
            "\n",
            "tokenizer = SimpleTokenizerV2(vocab)\n",
            "encoded = tokenizer.encode(text)\n",
            "# tokenizer.int_to_token.keys()\n",
            "print(encoded)\n",
            "decoded = tokenizer.decode(encoded)\n",
            "print(decoded)\n",
            "print(tokenizer.decode(tokenizer.encode(text)))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 108,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
                  "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
               ]
            }
         ],
         "source": [
            "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "text = (\n",
            "\"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
            "\"of someunknownPlace.\"\n",
            ")\n",
            "encoded = bpe_tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
            "print(encoded)\n",
            "strings = bpe_tokenizer.decode(encoded)\n",
            "print(strings)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 109,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[33901, 86, 343, 86, 220, 959]\n",
                  "Akwirw ier\n"
               ]
            }
         ],
         "source": [
            "new_word = \"Akwirw ier\"\n",
            "\n",
            "encoded = bpe_tokenizer.encode(new_word)\n",
            "print(encoded)\n",
            "decoded = bpe_tokenizer.decode(encoded)\n",
            "print(decoded)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 110,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ']\n",
                  "20479\n",
                  "['year', 'years', 'yellow', 'yet', 'you', 'younger', 'your', 'yourself', '<|unk|>', '<|endoftext|>']\n",
                  "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]\n"
               ]
            }
         ],
         "source": [
            "with open(\"the-verdict.txt\", \"r\") as f:\n",
            "    lines = f.read()\n",
            "\n",
            "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', lines)\n",
            "print(preprocessed[:10])\n",
            "preprocessed = [item for item in preprocessed if item.strip()]\n",
            "print(len(lines))\n",
            "all_words = sorted(set(preprocessed))\n",
            "all_words.extend([\"<|unk|>\", \"<|endoftext|>\"])\n",
            "print(all_words[-10:])\n",
            "vocab_size = len(all_words)\n",
            "enc_text = bpe_tokenizer.encode(lines)\n",
            "vocab_size = len(enc_text)\n",
            "print(enc_text[:10])\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 111,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[290, 4920]\n",
                  "[4920, 2241]\n",
                  " and established -->  established himself\n"
               ]
            }
         ],
         "source": [
            "block_size = 2\n",
            "enc_sample = enc_text[50:]\n",
            "for i in range(block_size):\n",
            "    x = enc_sample[i:block_size]\n",
            "    y = enc_sample[i+1:i+block_size+1]\n",
            "    print(x)\n",
            "    print(y)\n",
            "    print(bpe_tokenizer.decode(x), \"-->\", bpe_tokenizer.decode(y))\n",
            "    break\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 112,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(tensor([  44,  149, 1003,   57]), tensor([ 149, 1003,   57,   38]))"
                  ]
               },
               "execution_count": 112,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import torch\n",
            "from torch.utils.data import DataLoader, Dataset\n",
            "\n",
            "class GPTDatasetV1(Dataset):\n",
            "    def __init__(self, text, tokenizer, max_length, stride):\n",
            "        self.input_ids = []\n",
            "        self.target_ids = []\n",
            "        self.encoded = tokenizer.encode(text)\n",
            "        #max_length = block_size or context_length, so need to substract max_length from range as that will be size of the sliced array \n",
            "        for i in range(0, len(self.encoded) - max_length, stride):\n",
            "            input_chunk = self.encoded[i:i+max_length]\n",
            "            targets = self.encoded[i+1:i+max_length+1]\n",
            "            self.input_ids.append(torch.tensor(input_chunk))\n",
            "            self.target_ids.append(torch.tensor(targets))\n",
            "    \n",
            "    def __len__(self):\n",
            "        return len(self.input_ids)\n",
            "    \n",
            "    def __getitem__(self, idx):\n",
            "        return (self.input_ids[idx], self.target_ids[idx])\n",
            "\n",
            "\n",
            "dataset = GPTDatasetV1(lines, tokenizer, 4, 1)\n",
            "dataset[1]\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 113,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([4, 4])"
                  ]
               },
               "execution_count": 113,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "def create_dataloader_v1(text, batch_size, max_length, stride, shuffle=True, drop_last=True, num_workers=0):\n",
            "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "    dataset = GPTDatasetV1(text, tokenizer=tokenizer, max_length=max_length, stride=stride)\n",
            "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, drop_last=drop_last, shuffle=shuffle)\n",
            "    return dataloader\n",
            "\n",
            "dataloader = create_dataloader_v1(lines, batch_size=4, max_length=4, stride=1, shuffle=False)\n",
            "\n",
            "first_batch = next(iter(dataloader))\n",
            "\n",
            "first_batch[0].shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 114,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[tensor([[   40,   367,  2885,  1464],\n",
                     "         [ 1464,  1807,  3619,   402],\n",
                     "         [  402,   271, 10899,  2138],\n",
                     "         [ 2138,   257,  7026, 15632]]),\n",
                     " tensor([[  367,  2885,  1464,  1807],\n",
                     "         [ 1807,  3619,   402,   271],\n",
                     "         [  271, 10899,  2138,   257],\n",
                     "         [  257,  7026, 15632,   438]])]"
                  ]
               },
               "execution_count": 114,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "dataloader = create_dataloader_v1(lines, batch_size=4, max_length=4, stride=3, shuffle=False)\n",
            "\n",
            "first_batch = next(iter(dataloader))\n",
            "\n",
            "first_batch"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Chapter 3\n",
            "Prior to transformers, RNNs were a popular architecture for NLP tasks such as machine translation. These networks consist of an encoder and decoder network. The encoder processes a sequence of tokens, where the first token is passed to the first hidden layer, the second is passed to the second layer state AS WELL AS the hidden state of the first token. The last hidden state of the encoder is passed to the decoder network, therefore it relies solely on the encapsulated context from the last hidden state of the encoder. It does not have direct access to previous tokens/hidden states (e.g words in a sentence), but only the last generated hidden state from the encoder. Although the the task of the encoder is to generate a sufficiently rich representation of the entire embedded sentence, this is remains limited to short sequence lengths and highlights the main limitation of the classical RNN architecture.\n",
            "\n",
            "#### Bahdanau attention (2014)\n",
            "\n",
            "Modified the encoder-decoder RNN so the decoder can selectively access different parts of the input sequence at each decoding step. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Scaled dot product attention\n",
            "\n",
            "The following implements self-attention where the dot products are scaled by the dimension of the compute key matrix encoding representations of the tokens after apply the key weights matrix. The reason for normalised and scaling these values is to improve training performance. For large architectures that use a large embedding dimension (e.g 1000 for GPT models), large dot products can result in very small gradients during backpropagation due to the softmax function. If one value dominates output from the dot product, the softmax normalisation will accordingly scale all the remaining values to very small values. Scaling by the sqrt of the embedding dim prevents these very large values from dominating the normalisation.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 115,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor([[ 1.9316,  0.4313, -0.7109],\n",
                  "        [ 0.6485, -0.1284,  0.5325],\n",
                  "        [ 0.8215, -0.1826,  0.3178],\n",
                  "        [-0.9738, -0.1506,  1.1969]], grad_fn=<SelectBackward0>)\n",
                  "input shape torch.Size([4, 4, 3])\n",
                  "torch.Size([2])\n",
                  "torch.Size([4, 2])\n",
                  "tensor(0.0254, grad_fn=<AddBackward0>)\n",
                  "tensor(-0.6723, grad_fn=<AddBackward0>)\n",
                  "tensor(-0.6723, grad_fn=<DotBackward0>)\n",
                  "attention_scores_2 shape: torch.Size([4])\n",
                  "values shape: torch.Size([4, 2])\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor([-0.5963,  0.6468], grad_fn=<SqueezeBackward4>)"
                  ]
               },
               "execution_count": 115,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\n",
            "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "vocab_size = tokenizer.n_vocab\n",
            "output_dim = 3  # for illustration\n",
            "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
            "input_ids, target_ids = first_batch\n",
            "inputs = token_embedding_layer(input_ids)\n",
            "\n",
            "print(inputs[1])\n",
            "print(\"input shape\", inputs.shape)\n",
            "\n",
            "x2 = inputs[1][1]\n",
            "d_in = x2.shape[0]\n",
            "d_out = 2\n",
            "\n",
            "torch.manual_seed(0)\n",
            "W_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "K_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "V_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "\n",
            "\n",
            "x2_query = x2 @ W_query # query vector for 2nd token in the first example of the batch\n",
            "keys = inputs[1] @ K_query # key matrix for all tokens in the first example of the batch\n",
            "values = inputs[1] @ V_query # value matrix for all tokens in the first example of the batch\n",
            "\n",
            "print(x2_query.shape) # query vector\n",
            "print(keys.shape) # \n",
            "\n",
            "# attention score\n",
            "tmp_score = 0\n",
            "x2_key = keys[1]\n",
            "for i in range(2):\n",
            "    tmp_score += x2_query[i] * x2_key[i]\n",
            "    print(tmp_score)\n",
            "attention_score_22 = x2_query.dot(keys[1])\n",
            "print(attention_score_22)\n",
            "\n",
            "attention_scores_2 = x2_query @ keys.T\n",
            "# softmax normalisation\n",
            "d_k = keys.shape[1] # embedding dimension of the keys\n",
            "# SCALED DOT PRODUCT ATTENTION\n",
            "attention_weights_2 = torch.nn.functional.softmax(attention_scores_2 / (d_k ** 0.5), dim=-1)\n",
            "attention_weights_2\n",
            "\n",
            "# context vector calculation\n",
            "print(f\"attention_scores_2 shape: {attention_scores_2.shape}\")\n",
            "print(f\"values shape: {values.shape}\")\n",
            "context_vector_2 = attention_weights_2 @ values\n",
            "context_vector_2 # represents relative importance of all the input tokens wrto the 2nd token in the first example of the batch\n",
            "\n",
            "context_vector_2\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 116,
         "metadata": {},
         "outputs": [],
         "source": [
            "class SelfAttention_v1(torch.nn.Module):\n",
            "    def __init__(self, d_in, d_out):\n",
            "        super().__init__()\n",
            "        self.Q = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "        self.K = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "        self.V = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
            "    \n",
            "    def forward(self, x):\n",
            "        query = x @ self.Q\n",
            "        keys = x @ self.K\n",
            "        values = x @ self.V\n",
            "        attention_scores = query @ keys.T\n",
            "        d_k = keys.shape[1]\n",
            "        # rescale the attention scores because dot products can be large when embedding dimension is large\n",
            "        # i.e the sum is taken over the embedding dimension, so many values result in a large dot product\n",
            "        # results in very small gradients\n",
            "        attention_weights = torch.nn.functional.softmax(attention_scores / (d_k ** 0.5), dim=-1)\n",
            "        context_vector = attention_weights @ values\n",
            "        return context_vector\n",
            "\n",
            "class SelfAttention_v2(torch.nn.Module):\n",
            "    def __init__(self, d_in, d_out, qkv_bias: bool = False):\n",
            "        super().__init__()\n",
            "        # proper initialization of weights in torch nn.Linear modules\n",
            "        self.Q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.K = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "        self.V = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
            "    \n",
            "    def forward(self, x):\n",
            "        query = self.Q(x)\n",
            "        keys = self.K(x)\n",
            "        values = self.V(x)\n",
            "        attention_scores = query @ keys.T\n",
            "        d_k = keys.shape[1]\n",
            "        attention_weights = torch.nn.functional.softmax(attention_scores / (d_k ** 0.5), dim=-1)\n",
            "        context_vector = attention_weights @ values\n",
            "        return context_vector\n",
            "\n",
            "    \n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 117,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([4, 4, 3])"
                  ]
               },
               "execution_count": 117,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "inputs.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 118,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "d_in 3, d_out 2\n",
                  "torch.Size([4, 3])\n",
                  "sa_v1\n",
                  "tensor([-3.1752,  1.4927], grad_fn=<SelectBackward0>)\n",
                  "sa_v2\n",
                  "tensor([ 0.1695, -0.2286], grad_fn=<SelectBackward0>)\n",
                  "torch.Size([3, 2])\n",
                  "torch.Size([2, 3])\n",
                  "updated sa_v1\n",
                  "tensor([ 0.1695, -0.2286], grad_fn=<SelectBackward0>)\n"
               ]
            }
         ],
         "source": [
            "# compare SelfAttentionV1 and V2\n",
            "d_in = inputs.shape[-1] # embedding dim\n",
            "d_out = 2\n",
            "print(f\"d_in {d_in}, d_out {d_out}\")\n",
            "sa_v1 = SelfAttention_v1(d_in=d_in, d_out=d_out)\n",
            "sa_v2 = SelfAttention_v2(d_in=d_in, d_out=d_out)\n",
            "\n",
            "x2 = inputs[1]\n",
            "print(x2.shape)\n",
            "sa_v1_mat = sa_v1(inputs[1])\n",
            "sa_v2_mat = sa_v2(inputs[1])\n",
            "print(\"sa_v1\")\n",
            "print(sa_v1_mat[0])\n",
            "print(\"sa_v2\")\n",
            "print(sa_v2_mat[0])\n",
            "\n",
            "print(sa_v1.Q.shape)\n",
            "print(sa_v2.Q.weight.shape)\n",
            "\n",
            "sa_v1.Q = torch.nn.Parameter(sa_v2.Q.weight.T)\n",
            "sa_v1.V = torch.nn.Parameter(sa_v2.V.weight.T)\n",
            "sa_v1.K = torch.nn.Parameter(sa_v2.K.weight.T)\n",
            "print(\"updated sa_v1\")\n",
            "sa_v1_mat_up = sa_v1(inputs[1])\n",
            "print(sa_v1_mat_up[0])\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 119,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([4, 4, 2]) torch.Size([4, 4, 2])\n",
                  "context length 4\n",
                  "tensor([[0., 1., 1., 1.],\n",
                  "        [0., 0., 1., 1.],\n",
                  "        [0., 0., 0., 1.],\n",
                  "        [0., 0., 0., 0.]])\n",
                  "tensor([[False,  True,  True,  True],\n",
                  "        [False, False,  True,  True],\n",
                  "        [False, False, False,  True],\n",
                  "        [False, False, False, False]])\n",
                  "tensor([[[ 0.8849,    -inf,    -inf,    -inf],\n",
                  "         [ 0.4045, -0.0083,    -inf,    -inf],\n",
                  "         [-0.1649,  0.3560, -0.8862,    -inf],\n",
                  "         [ 1.5401,  0.4057, -0.8526,  2.3049]],\n",
                  "\n",
                  "        [[ 2.3049,    -inf,    -inf,    -inf],\n",
                  "         [ 0.1930, -0.0741,    -inf,    -inf],\n",
                  "         [ 0.4634, -0.0604,  0.0217,    -inf],\n",
                  "         [-1.6697, -0.0295, -0.1952,  1.2006]],\n",
                  "\n",
                  "        [[ 1.2006,    -inf,    -inf,    -inf],\n",
                  "         [-0.4966,  0.1007,    -inf,    -inf],\n",
                  "         [-0.7863,  0.1697,  0.6142,    -inf],\n",
                  "         [-0.1168,  0.0141,  0.1295, -0.0224]],\n",
                  "\n",
                  "        [[-0.0224,    -inf,    -inf,    -inf],\n",
                  "         [-0.2155, -0.8818,    -inf,    -inf],\n",
                  "         [ 0.0098, -0.4919,  0.4459,    -inf],\n",
                  "         [-0.0864, -0.2078, -0.1607,  0.5013]]], grad_fn=<MaskedFillBackward0>)\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
                     "         [0.5725, 0.4275, 0.0000, 0.0000],\n",
                     "         [0.3283, 0.4745, 0.1971, 0.0000],\n",
                     "         [0.2985, 0.1338, 0.0550, 0.5127]],\n",
                     "\n",
                     "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
                     "         [0.5471, 0.4529, 0.0000, 0.0000],\n",
                     "         [0.4128, 0.2850, 0.3021, 0.0000],\n",
                     "         [0.0683, 0.2179, 0.1938, 0.5200]],\n",
                     "\n",
                     "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
                     "         [0.3960, 0.6040, 0.0000, 0.0000],\n",
                     "         [0.1767, 0.3475, 0.4758, 0.0000],\n",
                     "         [0.2296, 0.2518, 0.2732, 0.2454]],\n",
                     "\n",
                     "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
                     "         [0.6157, 0.3843, 0.0000, 0.0000],\n",
                     "         [0.3265, 0.2290, 0.4445, 0.0000],\n",
                     "         [0.2282, 0.2094, 0.2165, 0.3458]]], grad_fn=<SoftmaxBackward0>)"
                  ]
               },
               "execution_count": 119,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# masked self-attention (causal self-attention)\n",
            "# ensures that no current position is influenced by future positions (e.g for generative tasks)\n",
            "queries = sa_v2.Q(inputs)\n",
            "keys = sa_v2.K(inputs)\n",
            "print(queries.shape, keys.shape)\n",
            "attention_scores = queries @ keys.transpose(1,2)\n",
            "# normalisation of scores to they form a probability distribution summing to 1 - this is applied along the embedding dim \n",
            "attention_weights = torch.nn.functional.softmax(attention_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
            "\n",
            "context_length = inputs.shape[1]\n",
            "print(f\"context length {context_length}\")\n",
            "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
            "print(mask)\n",
            "print(mask.bool())\n",
            "# negative infinity approaches 0 in softmax function (because e-inf approaches 0)\n",
            "attention_scores_masked = attention_scores.masked_fill_(mask.bool(), -torch.inf)\n",
            "print(attention_scores_masked)\n",
            "# normalised weights\n",
            "attention_weights = torch.nn.functional.softmax((attention_scores_masked) / keys.shape[-1] ** 0.5, dim=-1)\n",
            "attention_weights"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 120,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor([[2., 2., 0., 2.],\n",
                  "        [2., 0., 0., 0.],\n",
                  "        [0., 2., 0., 2.],\n",
                  "        [2., 2., 2., 2.]])\n"
               ]
            }
         ],
         "source": [
            "# Dropout\n",
            "# only applied during training, not inference\n",
            "torch.manual_seed(123)\n",
            "dropout = torch.nn.Dropout(0.5)\n",
            "example = torch.ones((context_length, context_length))\n",
            "# to compensate for the reduction in active units, the un-zero'd values are scaled by (original_val / dropout_prob (0.5))\n",
            "# 1 / 0.5 = 2\n",
            "# this ensures the overall influence of the weight is consistent at both training and inference time\n",
            "print(dropout(example))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 121,
         "metadata": {},
         "outputs": [],
         "source": [
            "class CausalAttention(torch.nn.Module):\n",
            "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias: bool= False):\n",
            "        super().__init__()\n",
            "        self.d_out = d_out\n",
            "        self.dropout = torch.nn.Dropout(dropout)\n",
            "        self.Q = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.K = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.V = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
            "    \n",
            "    def forward(self, x):\n",
            "        batch, num_token, d_in = x.shape\n",
            "        keys = self.K(x)\n",
            "        queries = self.Q(x)\n",
            "        values = self.V(x)\n",
            "        attn_scores = queries @ keys.transpose(1, 2)\n",
            "        attn_scores.masked_fill_(self.mask.bool()[:num_token, :num_token], -torch.inf)\n",
            "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
            "        attn_weights = self.dropout(attn_weights)\n",
            "        context_vec = attn_weights @ values\n",
            "        return context_vec\n",
            "        \n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 122,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([4, 4, 2])"
                  ]
               },
               "execution_count": 122,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "context_length = inputs.shape[1]\n",
            "ca=CausalAttention(d_in, d_out, context_length, 0.0)\n",
            "context_vecs = ca(inputs)\n",
            "context_vecs.shape\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 123,
         "metadata": {},
         "outputs": [],
         "source": [
            "# multihead attention\n",
            "# apply multiple query key and value matrices (one for each head) in parallel\n",
            "\n",
            "class MultiHeadAttention(torch.nn.Module):\n",
            "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
            "        super().__init__()\n",
            "        assert (d_out % num_heads == 0), f\"d_out {d_out} must be divisible by num heads {num_heads}\"\n",
            "        self.d_out = d_out\n",
            "        self.num_heads = num_heads\n",
            "        self.head_dim = d_out // num_heads\n",
            "        self.W_query = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.W_key = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.W_value = torch.nn.Linear(in_features=d_in, out_features=d_out)\n",
            "        self.out_proj = torch.nn.Linear(in_features=d_out, out_features=d_out)\n",
            "        self.dropout = torch.nn.Dropout(dropout)\n",
            "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
            "    \n",
            "    def forward(self, x):\n",
            "        batch, num_token, d_in = x.shape\n",
            "        keys = self.W_key(x)\n",
            "        queries = self.W_query(x)\n",
            "        values = self.W_value(x)\n",
            "        keys = keys.view(batch, num_token, self.num_heads, self.head_dim)\n",
            "        queries = queries.view(batch, num_token, self.num_heads, self.head_dim)\n",
            "        values = values.view(batch, num_token, self.num_heads, self.head_dim)\n",
            "        keys = keys.transpose(1,2)\n",
            "        queries = queries.transpose(1,2)\n",
            "        values = values.transpose(1,2)\n",
            "        attn_scores = queries @ keys.transpose(2, 3)\n",
            "        mask_bool = self.mask.bool()[:num_token, :num_token]\n",
            "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
            "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
            "        attn_weights = self.dropout(attn_weights)\n",
            "        context_vec = attn_weights @ values\n",
            "        # contiguous makes a copy of the tensor with the final memory layout specified by the tensor shape\n",
            "        context_vec = context_vec.contiguous().view(batch, num_token, self.d_out)\n",
            "        # project layer\n",
            "        context_vec = self.out_proj(context_vec)\n",
            "        return context_vec\n",
            "        \n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 124,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.Size([4, 4, 2])"
                  ]
               },
               "execution_count": 124,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "torch.manual_seed(123)\n",
            "\n",
            "batch_size, context_length, d_in = inputs.shape\n",
            "d_out = 2\n",
            "mha = MultiHeadAttention(d_in, d_out, context_length, 0.5, num_heads=2)\n",
            "out = mha(inputs)\n",
            "out.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 125,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([2, 1024])\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "torch.Size([2, 1024, 768])"
                  ]
               },
               "execution_count": 125,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# gpt-2 sized MHA\n",
            "\n",
            "embedding_dim = 768\n",
            "num_heads = 12\n",
            "context_length = 1024\n",
            "\n",
            "dataloader = create_dataloader_v1(lines, batch_size=2, max_length=context_length, stride=1, shuffle=False)\n",
            "first_batch = next(iter(dataloader))\n",
            "print(first_batch[0].shape)\n",
            "\n",
            "vocab_size = tokenizer.n_vocab\n",
            "token_embedding_layer = torch.nn.Embedding(vocab_size, embedding_dim)\n",
            "input_ids, target_ids = first_batch\n",
            "inputs = token_embedding_layer(input_ids)\n",
            "\n",
            "inputs[0].shape\n",
            "\n",
            "mha = MultiHeadAttention(d_in=768, d_out=768, context_length=context_length, dropout=0.2, num_heads=12)\n",
            "\n",
            "out = mha(inputs)\n",
            "\n",
            "out.shape"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 126,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "(tensor([[-1.3039e-08, -9.3132e-09, -6.2088e-10,  ..., -3.1044e-09,\n",
                     "          -7.4506e-09, -4.9671e-09],\n",
                     "         [-9.3132e-09, -6.2088e-10, -1.4901e-08,  ..., -7.4506e-09,\n",
                     "          -4.9671e-09,  2.4835e-09]], grad_fn=<MeanBackward1>),\n",
                     " tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
                     "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
                     "        grad_fn=<VarBackward0>))"
                  ]
               },
               "execution_count": 126,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# GPT-2 implementation\n",
            "# vocab size is determined by the BPE tokenizer\n",
            "GPT_CONFIG_124M = {\"vocab_size\": 50257, \"context_length\": 1024, \"emb_dim\": 768, \"n_heads\": 12, \"n_layers\": 12, \"drop_rate\": 0.1, \"qkv_bias\": False}\n",
            "\n",
            "class LayerNorm(torch.nn.Module):\n",
            "    def __init__(self, emb_dim):\n",
            "        super().__init__()\n",
            "        self.eps = 1e-5\n",
            "        # Parameter = trainable parameter in torch\n",
            "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
            "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
            "\n",
            "    def forward(self, x):\n",
            "        # dim = -1  --> embedding dimension\n",
            "        mean = x.mean(dim=-1, keepdim=True)\n",
            "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
            "        norm_x = (x-mean) / torch.sqrt(var + self.eps)\n",
            "        return self.scale * norm_x + self.shift\n",
            "\n",
            "first_batch\n",
            "embedding_dim = 768 \n",
            "ln = LayerNorm(embedding_dim)\n",
            "out_ln = ln(inputs)\n",
            "# expect mean = 0 and var = 1\n",
            "out_ln.mean(dim=-1), out_ln.var(dim=-1, unbiased=False)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 127,
         "metadata": {},
         "outputs": [],
         "source": [
            "# GELU activation function\n",
            "\n",
            "class GELU(torch.nn.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "    \n",
            "    def forward(self, x):\n",
            "        value = 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
            "        return value\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 128,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 800x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# GELU compared to RELU\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "gelu, relu = GELU(), torch.nn.ReLU()\n",
            "\n",
            "x = torch.linspace(-3, 3, 100)\n",
            "\n",
            "gelu_out = gelu(x)\n",
            "relu_out = relu(x)\n",
            "\n",
            "plt.figure(figsize=(8, 3))\n",
            "for i, (y, label) in enumerate(zip([gelu_out, relu_out], [\"GELU\",\"RELU\"]), 1):\n",
            "    plt.subplot(1, 2, i)\n",
            "    plt.plot(x, y)\n",
            "    plt.title(f\"{label} activation function\")\n",
            "    plt.xlabel(\"x\")\n",
            "    plt.ylabel(f\"{label}(x)\")\n",
            "plt.tight_layout()\n",
            "plt.show()\n",
            "\n",
            "# GELU is a smooth, non-linear function that is differentiable at almost any negative value (except ~ -0.75). \n",
            "# Better optimisation due to:\n",
            "# 1. smoothness\n",
            "# 2. differential for negative values so these can contribute to the gradients/optimisation process"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 129,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n"
               ]
            }
         ],
         "source": [
            "# Feedforward with GELU\n",
            "# Feedforward layers enable richer representations through expansion to higher dimensions \n",
            "\n",
            "class FeedForward(torch.nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.layers = torch.nn.Sequential(torch.nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']), GELU(), torch.nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']))\n",
            "    \n",
            "    def forward(self, x):\n",
            "        out = self.layers(x)\n",
            "        return out\n",
            "\n",
            "print(GPT_CONFIG_124M)\n",
            "\n",
            "ffn = FeedForward(GPT_CONFIG_124M)\n",
            "x = torch.randn((2, 3, 768))\n",
            "out = ffn(x)\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 130,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "no skip\n",
                  "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
                  "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
                  "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
                  "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
                  "layers.4.0.weight has gradient mean of 0.005049645435065031\n",
                  "skip\n",
                  "layers.0.0.weight has gradient mean of 0.0014432291500270367\n",
                  "layers.1.0.weight has gradient mean of 0.004846951924264431\n",
                  "layers.2.0.weight has gradient mean of 0.004138893447816372\n",
                  "layers.3.0.weight has gradient mean of 0.005915115587413311\n",
                  "layers.4.0.weight has gradient mean of 0.032659437507390976\n"
               ]
            }
         ],
         "source": [
            "# Skip connections\n",
            "# Create an alternative path for the gradient flow by adding the output from layer to the output of a later layer \n",
            "# First applied in \"residual\" networks in computer vision\n",
            "# Help with optimisation process as the addition of the input (e.g x) to the output from a layer increase the magnitude of the values\n",
            "# Thus helps with the vanishing gradient problem\n",
            "\n",
            "class DeepNeuralNetwork(torch.nn.Module):\n",
            "    def __init__(self, layer_sizes, use_skip):\n",
            "        super().__init__()\n",
            "        self.use_skip = use_skip\n",
            "        self.layers = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()), torch.nn.Sequential(torch.nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()), torch.nn.Sequential(torch.nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()), torch.nn.Sequential(torch.nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()), torch.nn.Sequential(torch.nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())])\n",
            "    \n",
            "    def forward(self, x):\n",
            "        for layer in self.layers:\n",
            "            out = layer(x)\n",
            "            if self.use_skip and x.shape == out.shape:\n",
            "                x = out + x\n",
            "            else:\n",
            "                x = out\n",
            "        return x\n",
            "                \n",
            "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
            "sample_input = torch.tensor([[1.0, 0., -1]])\n",
            "torch.manual_seed(123)\n",
            "model_no_skip = DeepNeuralNetwork(layer_sizes, False)\n",
            "\n",
            "def print_gradients(model, x):\n",
            "    output = model(x)\n",
            "    target = torch.tensor([[0.]])\n",
            "    loss = torch.nn.MSELoss()\n",
            "    loss = loss(output, target)\n",
            "    loss.backward()\n",
            "    for name, param in model.named_parameters():\n",
            "        if 'weight' in name:\n",
            "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n",
            "\n",
            "\n",
            "print(\"no skip\")\n",
            "print_gradients(model_no_skip, sample_input)\n",
            "\n",
            "print(\"skip\")\n",
            "model_skip = DeepNeuralNetwork(layer_sizes, True)\n",
            "print_gradients(model_skip, sample_input)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 131,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Input shape: torch.Size([2, 4, 768])\n",
                  "Output shape: torch.Size([2, 4, 768])\n"
               ]
            }
         ],
         "source": [
            "# Transformer implementation - combines all of the above\n",
            "\n",
            "class TransformerBlock(torch.nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.att = MultiHeadAttention(\n",
            "            d_in=cfg[\"emb_dim\"],\n",
            "            d_out=cfg[\"emb_dim\"],\n",
            "            context_length=cfg[\"context_length\"],\n",
            "            num_heads=cfg[\"n_heads\"],\n",
            "            dropout=cfg[\"drop_rate\"],\n",
            "            qkv_bias=cfg[\"qkv_bias\"])\n",
            "        self.ff = FeedForward(cfg)\n",
            "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
            "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
            "        self.drop_shortcut = torch.nn.Dropout(cfg[\"drop_rate\"])\n",
            "    def forward(self, x):\n",
            "        shortcut = x\n",
            "        # layer norm\n",
            "        x = self.norm1(x)\n",
            "        # multihead attn\n",
            "        x = self.att(x)\n",
            "        # dropout\n",
            "        x = self.drop_shortcut(x)\n",
            "        # skip connection\n",
            "        x = x + shortcut\n",
            "        shortcut = x\n",
            "        # layer norm\n",
            "        x = self.norm2(x)\n",
            "        # feedforward\n",
            "        x = self.ff(x)\n",
            "        # dropout\n",
            "        x = self.drop_shortcut(x)\n",
            "        # skip connection\n",
            "        x = x + shortcut\n",
            "        return x\n",
            "\n",
            "\n",
            "torch.manual_seed(123)\n",
            "x = torch.rand(2, 4, 768)\n",
            "block = TransformerBlock(GPT_CONFIG_124M)\n",
            "output = block(x)\n",
            "print(\"Input shape:\", x.shape)\n",
            "print(\"Output shape:\", output.shape)\n",
            "\n",
            "# The preservation of shape throughout the transformer block\n",
            "# architecture is not incidental but a crucial aspect of its\n",
            "# design. This design enables its effective application across a\n",
            "# wide range of sequence-to-sequence tasks, where each\n",
            "# output vector directly corresponds to an input vector,\n",
            "# maintaining a one-to-one relationship"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 132,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([2, 1024])\n",
                  "Input batch:\n",
                  " tensor([[   40,   367,  2885,  ...,   691, 12226,   318],\n",
                  "        [  367,  2885,  1464,  ..., 12226,   318,   284]])\n",
                  "\n",
                  "Output shape: torch.Size([2, 1024, 50257])\n",
                  "tensor([[[ 0.1187, -0.1796, -0.6110,  ...,  0.0130, -1.3194,  0.1855],\n",
                  "         [ 0.3433, -0.4382,  0.3009,  ..., -0.6556, -1.0232, -0.4446],\n",
                  "         [ 0.0872,  0.0704, -1.1122,  ..., -0.0253, -0.9942, -0.1097],\n",
                  "         ...,\n",
                  "         [ 0.0912,  1.0045,  0.0662,  ...,  0.1016, -0.2378,  0.0536],\n",
                  "         [ 0.0238,  0.8239, -0.7458,  ...,  0.1565, -0.5105, -0.4867],\n",
                  "         [-0.2985, -0.6460, -0.3411,  ..., -0.4631, -0.3258, -0.0331]],\n",
                  "\n",
                  "        [[-0.0576, -0.7426, -0.7723,  ...,  0.1837, -0.7695, -0.3656],\n",
                  "         [ 0.6787, -0.1122,  0.3471,  ..., -0.5583, -1.1185, -0.3215],\n",
                  "         [ 0.9600, -0.2068, -1.1007,  ...,  0.2360, -0.9795, -0.9828],\n",
                  "         ...,\n",
                  "         [-0.4394,  0.0363, -0.4366,  ..., -0.2182, -1.5601, -0.4550],\n",
                  "         [ 0.2571,  1.3750, -0.5499,  ..., -0.2535,  0.1757, -0.4047],\n",
                  "         [-0.6850,  0.3276, -0.8184,  ...,  0.4380, -0.2520, -0.1804]]],\n",
                  "       grad_fn=<UnsafeViewBackward0>)\n"
               ]
            }
         ],
         "source": [
            "# GPT Model\n",
            "from torch import nn\n",
            "\n",
            "class GPTModel(nn.Module):\n",
            "    def __init__(self, cfg):\n",
            "        super().__init__()\n",
            "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
            "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
            "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
            "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
            "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
            "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
            "\n",
            "    def forward(self, in_idx):\n",
            "        batch_size, seq_len = in_idx.shape\n",
            "        tok_embeds = self.tok_emb(in_idx)\n",
            "        #1\n",
            "        pos_embeds = self.pos_emb(\n",
            "        torch.arange(seq_len, device=in_idx.device)\n",
            "        )\n",
            "        x = tok_embeds + pos_embeds\n",
            "        x = self.drop_emb(x)\n",
            "        x = self.trf_blocks(x)\n",
            "        x = self.final_norm(x)\n",
            "        logits = self.out_head(x)\n",
            "        return logits\n",
            "\n",
            "torch.manual_seed(123)\n",
            "model = GPTModel(GPT_CONFIG_124M)\n",
            "print(first_batch[0].shape)\n",
            "out = model(first_batch[0])\n",
            "print(\"Input batch:\\n\", first_batch[0])\n",
            "print(\"\\nOutput shape:\", out.shape)\n",
            "print(out)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 133,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Total number of parameters: 163,037,184\n",
                  "Token embedding layer shape: torch.Size([50257, 768])\n",
                  "Output layer shape: torch.Size([50257, 768])\n",
                  "Number of trainable parameters considering weight tying: 124,439,808\n"
               ]
            }
         ],
         "source": [
            "total_params = sum(p.numel() for p in model.parameters())\n",
            "print(f\"Total number of parameters: {total_params:,}\")\n",
            "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
            "print(\"Output layer shape:\", model.out_head.weight.shape)\n",
            "\n",
            "total_params_gpt2 = (\n",
            "total_params - sum(p.numel()\n",
            "for p in model.out_head.parameters())\n",
            ")\n",
            "print(f\"Number of trainable parameters \"\n",
            "f\"considering weight tying: {total_params_gpt2:,}\"\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 134,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "feedfordward params 56669184, attn params 28348416\n"
               ]
            }
         ],
         "source": [
            "# exercise\n",
            "# Calculate and compare the number of parameters that are\n",
            "# contained in the feed forward module and those that are\n",
            "# contained in the multi-head attention module.\n",
            "\n",
            "feedforward_params = 0\n",
            "attn_params = 0\n",
            "for i in range(len(model.trf_blocks)):\n",
            "    feedforward_params+= sum(p.numel() for p in model.trf_blocks[i].ff.parameters())\n",
            "    attn_params += sum(p.numel() for p in model.trf_blocks[i].att.parameters())\n",
            "print(f\"feedfordward params {feedforward_params}, attn params {attn_params}\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 135,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Total size of the model: 621.94 MB\n"
               ]
            }
         ],
         "source": [
            "total_size_bytes = total_params * 4 # 4 bytes per float32 parameter\n",
            "total_size_mb = total_size_bytes / (1024 * 1024)\n",
            "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 136,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "large params 838359040\n",
                  "large model size 3198.09 MB\n"
               ]
            }
         ],
         "source": [
            "# exercise\n",
            "# implement GPT2-large and count params\n",
            "\n",
            "GPT_CONFIG_124M\n",
            "GPT_CONFIG_L = {\"vocab_size\": 50257, \"context_length\": 1024, \"emb_dim\": 1280, \"n_heads\": 20, \"n_layers\": 36, \"drop_rate\": 0.1, \"qkv_bias\": False}\n",
            "\n",
            "large_model = GPTModel(GPT_CONFIG_L)\n",
            "large_params = sum(p.numel() for p in large_model.parameters())\n",
            "large_size = (large_params * 4) / (1024*1024)\n",
            "print(f\"large params {large_params}\")\n",
            "print(f\"large model size {large_size:.2f} MB\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 137,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "[15496, 314, 716]\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "'Hello I am Basdxjected Roosevelt rateoby FaceALL disappearsarmac'"
                  ]
               },
               "execution_count": 137,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# generate text\n",
            "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
            "    for _ in range(max_new_tokens):\n",
            "        idx_cond = idx[:, -context_size:]\n",
            "        with torch.no_grad():\n",
            "            logits = model(idx_cond)\n",
            "        # last \"timestep\"/token i.e model generated output vs context\n",
            "        logits = logits[:, -1, :]\n",
            "        probas = torch.softmax(logits, dim=-1)\n",
            "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
            "        # cat the predicted token to the context for the next iteration\n",
            "        idx = torch.cat((idx, idx_next), dim=1)\n",
            "    return idx\n",
            "\n",
            "start_context = \"Hello I am\"\n",
            "encoded = tokenizer.encode(start_context)\n",
            "print(encoded)\n",
            "enc_input = torch.tensor(encoded).unsqueeze(0)\n",
            "model.eval()\n",
            "next_iter = generate_text_simple(model, enc_input, 10, GPT_CONFIG_124M['context_length'])\n",
            "next_iter\n",
            "decoded_text = tokenizer.decode(next_iter.squeeze(0).tolist())\n",
            "decoded_text\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Chapter 5\n",
            "# Pretraining\n",
            "\n",
            "GPT_CONFIG_124M = {\n",
            "    \"vocab_size\": 50257,\n",
            "    \"context_length\": 256,\n",
            "    \"emb_dim\": 768,\n",
            "    \"n_heads\": 12,\n",
            "    \"n_layers\": 12,\n",
            "    \"drop_rate\": 0.1,\n",
            "    \"qkv_bias\": False\n",
            "}\n",
            "torch.manual_seed(123)\n",
            "model = GPTModel(GPT_CONFIG_124M)\n",
            "model.eval();"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 139,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output text:\n",
                  " Every effort moves you 107 Holo analystsaiden Behampamr raidinguro覚醒\n"
               ]
            }
         ],
         "source": [
            "def text_to_token_ids(text, tokenizer):\n",
            "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
            "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
            "    #1\n",
            "    return encoded_tensor\n",
            "def token_ids_to_text(token_ids, tokenizer):\n",
            "    flat = token_ids.squeeze(0)\n",
            "    return tokenizer.decode(flat.tolist())\n",
            "\n",
            "start_context = \"Every effort moves you\"\n",
            "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "\n",
            "token_ids = generate_text_simple(\n",
            "    model=model,\n",
            "    idx=text_to_token_ids(start_context, tokenizer),\n",
            "    max_new_tokens=10,\n",
            "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
            ")\n",
            "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 140,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Characters: 20479\n",
                  "Tokens: 5145\n"
               ]
            }
         ],
         "source": [
            "file_path = \"the-verdict.txt\"\n",
            "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
            "    text_data = file.read()\n",
            "total_characters = len(text_data)\n",
            "total_tokens = len(tokenizer.encode(text_data))\n",
            "print(\"Characters:\", total_characters)\n",
            "print(\"Tokens:\", total_tokens)\n",
            "\n",
            "train_ratio = 0.90\n",
            "split_idx = int(train_ratio * len(text_data))\n",
            "train_data = text_data[:split_idx]\n",
            "val_data = text_data[split_idx:]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 141,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "torch.manual_seed(123)\n",
            "train_loader = create_dataloader_v1(\n",
            "    train_data,\n",
            "    batch_size=2,\n",
            "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
            "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
            "    drop_last=True,\n",
            "    shuffle=True,\n",
            "    num_workers=0\n",
            ")\n",
            "val_loader = create_dataloader_v1(\n",
            "    val_data,\n",
            "    batch_size=2,\n",
            "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
            "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
            "    drop_last=False,\n",
            "    shuffle=False,\n",
            "    num_workers=0\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 142,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Train loader:\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n",
                  "\n",
                  "Validation loader:\n",
                  "torch.Size([2, 256]) torch.Size([2, 256])\n"
               ]
            }
         ],
         "source": [
            "print(\"Train loader:\")\n",
            "for x, y in train_loader:\n",
            "    print(x.shape, y.shape)\n",
            "print(\"\\nValidation loader:\")\n",
            "\n",
            "for x, y in val_loader:\n",
            "    print(x.shape, y.shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 143,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "train loss 10.99\n",
                  "val loss 10.97\n"
               ]
            }
         ],
         "source": [
            "def calc_loss_batch(train_batch, target_batch, model, device):\n",
            "    train_batch = train_batch.to(device)\n",
            "    target_batch = target_batch.to(device)\n",
            "    preds = model(train_batch)\n",
            "    # flatten converts preds [9, 2, 256] --> [18, 256]; target_batch [9, 2] --> [18]\n",
            "    loss = torch.nn.functional.cross_entropy(preds.flatten(0, 1), target_batch.flatten(0))\n",
            "    return loss\n",
            "\n",
            "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
            "    total_loss = 0.\n",
            "    if len(data_loader) == 0:\n",
            "        return float(\"nan\")\n",
            "    elif num_batches is None:\n",
            "        num_batches = len(data_loader)\n",
            "    else:\n",
            "        num_batches = min(num_batches, len(data_loader)) \n",
            "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
            "        if i < num_batches:\n",
            "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
            "            total_loss += loss.item()\n",
            "        else:\n",
            "            break\n",
            "    return total_loss / num_batches\n",
            "\n",
            "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
            "model.to(device)\n",
            "with torch.no_grad():\n",
            "    train_loss = calc_loss_loader(train_loader, model, device, 2)\n",
            "    val_loss = calc_loss_loader(train_loader, model, device, 2)\n",
            "print(f\"train loss {train_loss:.2f}\")\n",
            "print(f\"val loss {val_loss:.2f}\")\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 144,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Ep 1 (Step 000000): Train loss 9.680, Val loss 10.028\n",
                  "Ep 1 (Step 000005): Train loss 7.938, Val loss 8.265\n",
                  "Every effort moves you, the, the, the of the of the of the of the of the of the of the, of the of the of the of the of the of the of the of the of the of the of the of the of the of the of\n",
                  "Ep 2 (Step 000010): Train loss 6.516, Val loss 7.051\n",
                  "Ep 2 (Step 000015): Train loss 5.785, Val loss 6.538\n",
                  "Every effort moves you. \", and, and, and he was, and, and in the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of\n",
                  "Ep 3 (Step 000020): Train loss 4.923, Val loss 6.539\n",
                  "Ep 3 (Step 000025): Train loss 4.758, Val loss 6.240\n",
                  "Every effort moves you he was, in a was, in a little--I had been. Gisburn's was, in the, I had been to see it was a little of my, as he was a little of the picture--I had been was a\n",
                  "Ep 4 (Step 000030): Train loss 3.695, Val loss 6.204\n",
                  "Ep 4 (Step 000035): Train loss 3.142, Val loss 6.177\n",
                  "Every effort moves you know, I had been the picture, the--and the picture, and in the picture--and a little the fact, and in the. \"I the picture, he had the picture.          \n",
                  "Ep 5 (Step 000040): Train loss 2.439, Val loss 6.181\n",
                  "Every effort moves you know, and my dear, and he was not the fact with the in the and it was no--that was the women had been his pictures--his--as he had been his pictures--the quality of the my dear, and he was his\n"
               ]
            }
         ],
         "source": [
            "\n",
            "\n",
            "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
            "    model.eval() \n",
            "    with torch.no_grad():\n",
            "        train_loss = calc_loss_loader(\n",
            "            train_loader, model, device, num_batches=eval_iter\n",
            "        )\n",
            "        val_loss = calc_loss_loader(\n",
            "            val_loader, model, device, num_batches=eval_iter\n",
            "        )\n",
            "    model.train()\n",
            "    return train_loss, val_loss\n",
            "\n",
            "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
            "    model.eval()\n",
            "    context_size = model.pos_emb.weight.shape[0]\n",
            "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
            "    with torch.no_grad():\n",
            "        token_ids = generate_text_simple(\n",
            "            model=model, idx=encoded,\n",
            "            max_new_tokens=50, context_size=context_size\n",
            "        )\n",
            "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
            "    print(decoded_text.replace(\"\\n\", \" \"))\n",
            "    model.train()\n",
            "\n",
            "\n",
            "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,eval_freq, eval_iter, start_context, tokenizer):\n",
            "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
            "    tokens_seen, global_step = 0, -1\n",
            "    for epoch in range(num_epochs):\n",
            "        model.train()\n",
            "        for input_batch, target_batch in train_loader:\n",
            "            optimizer.zero_grad()\n",
            "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
            "            loss.backward()\n",
            "            optimizer.step()\n",
            "            tokens_seen += input_batch.numel()\n",
            "            global_step += 1\n",
            "            if global_step % eval_freq == 0:\n",
            "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
            "                train_losses.append(train_loss)\n",
            "                val_losses.append(val_loss)\n",
            "                track_tokens_seen.append(tokens_seen)\n",
            "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
            "                        f\"Train loss {train_loss:.3f}, \"\n",
            "                        f\"Val loss {val_loss:.3f}\"\n",
            "                )\n",
            "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
            "    return train_losses, val_losses, track_tokens_seen\n",
            "\n",
            "torch.manual_seed(123)\n",
            "model = GPTModel(GPT_CONFIG_124M)\n",
            "model.to(device)\n",
            "optimizer = torch.optim.AdamW(\n",
            "    model.parameters(),\n",
            "    lr=0.0004, weight_decay=0.1\n",
            ")\n",
            "num_epochs = 5\n",
            "train_losses, val_losses, tokens_seen = train_model_simple(\n",
            "    model, train_loader, val_loader, optimizer, device,\n",
            "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
            "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
            ")\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 145,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 500x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "from matplotlib.ticker import MaxNLocator\n",
            "\n",
            "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
            "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
            "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
            "    ax1.plot(\n",
            "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
            "    )\n",
            "    ax1.set_xlabel(\"Epochs\")\n",
            "    ax1.set_ylabel(\"Loss\")\n",
            "    ax1.legend(loc=\"upper right\")\n",
            "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
            "    ax2 = ax1.twiny()\n",
            "    #1\n",
            "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
            "    ax2.set_xlabel(\"Tokens seen\")\n",
            "    fig.tight_layout()\n",
            "    plt.show()\n",
            "\n",
            "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
            "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 146,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'every effort moves you know, and, and I was, the to the fact with the in the and it was, I had the the women'"
                  ]
               },
               "execution_count": 146,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "model.to(\"cpu\")\n",
            "model.eval()\n",
            "\n",
            "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
            "token_ids = generate_text_simple(model, text_to_token_ids(\"every effort moves you\", tokenizer), max_new_tokens=25, context_size=GPT_CONFIG_124M['context_length'])\n",
            "text = token_ids_to_text(token_ids, tokenizer)\n",
            "text\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 147,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "forward\n",
                  "forward\n",
                  "73 x closer\n",
                  "0 x every\n",
                  "0 x effort\n",
                  "582 x forward\n",
                  "2 x inches\n",
                  "0 x moves\n",
                  "0 x pizza\n",
                  "343 x toward\n"
               ]
            }
         ],
         "source": [
            "# text generation methods to introduce variation in the outpt\n",
            "vocab = {\n",
            "\"closer\": 0,\n",
            "\"every\": 1,\n",
            "\"effort\": 2,\n",
            "\"forward\": 3,\n",
            "\"inches\": 4,\n",
            "\"moves\": 5,\n",
            "\"pizza\": 6,\n",
            "\"toward\": 7,\n",
            "\"you\": 8,\n",
            "}\n",
            "inverse_vocab = {v: k for k, v in vocab.items()}\n",
            "next_token_logits = torch.tensor(\n",
            "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
            ")\n",
            "probas = torch.softmax(next_token_logits, dim=0)\n",
            "next_token_id = torch.argmax(probas).item()\n",
            "print(inverse_vocab[next_token_id])\n",
            "\n",
            "# probabilistic sampling process using multinomial function\n",
            "# multinomial function samples from the probas probability distribution num_samples times\n",
            "# multinomial = probs distribution for discrete events, where each event takes on a fixed set of discrete possible values \n",
            "# in this case, possible outcomes = vocab \n",
            "torch.manual_seed(123)\n",
            "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
            "print(inverse_vocab[next_token_id])\n",
            "\n",
            "def print_sampled_tokens(probas):\n",
            "    torch.manual_seed(123)\n",
            "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
            "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
            "    for i, freq in enumerate(sampled_ids):\n",
            "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
            "\n",
            "print_sampled_tokens(probas)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 148,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPrBJREFUeJzt3QeUU9X2P/BNE6RJ7yBNQaRJBykqHRRBUZqAtCcCgiIoIFWqNIHHUKQJ0uUJKkoRnnSQXqQqRXj0jgICwv2v7/6tm38SMsPMJJmcm/l+1spi5s5Mcidksu85Z5+9E1iWZQkREREZKWGoT4CIiIgix0BNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBEks88+DBAzlz5oykSpVKEiRIEOrTISKieMiyLPnzzz8lW7ZskjBh1GPmeBeoEaRz5swZ6tMgIiKSU6dOSY4cOaL8nngXqDGStp+c1KlTh/p0iIgoHrpx44YOGu2YFJV4F6jt6W4EaQZqIiIKpegswTKZjIiIyGAhDdTr1q2TV155RRfTcVWxZMmSR/7MmjVrpESJEpI0aVLJnz+/fPnll3FyrkRERPEuUN+8eVOKFSsmERER0fr+48ePS926deXFF1+U3bt3y/vvvy9t27aVFStWBP1ciYiIQiGka9S1a9fWW3RNmjRJ8uTJI6NGjdLPn3nmGdmwYYN8/vnnUrNmzSCeKRHF9TbKu3fvhvo0iGItSZIkkihRIgkERyWTbd68WapVq+ZxDAEaI+vI3LlzR2/umXZEZC4EaMyeIVgTOVmaNGkkS5YsftfscFSgPnfunGTOnNnjGD5H8L19+7Y8/vjjD/3M0KFDZcCAAXF4lkTkTxGIs2fP6kgEW1ceVQiCyNTX8a1bt+TChQv6edasWeNPoI6Nnj17SteuXR/au0ZE5vnnn3/0DQ4JpsmTJw/16RDFmj1wRLDOlCmTX9PgjgrUmEI4f/68xzF8jv3QvkbTgOxw3IiM0v+JKL52XeKr+/fv67+PPfZYqE+FyG/2xea9e/f8CtSOmlcqX768rF692uPYTz/9pMeJKHywDj+FgwQBeh2HNFD/9ddfus0KN0ACCT4+efKka9q6RYsWru9v3769HDt2TD766CM5dOiQTJgwQRYuXCgffPBByH4HIiKiYAppoN6+fbs899xzegOsJePjvn376udIKrGDNmBr1g8//KCjaOy/xjatqVOncmsWERGFrZCuUb/wwguaHRcZX1XH8DO7du0K8pkRkUly9/ghTh/vxLC6AZve7Nevn/Tv31/CSe7cuXVbbFRbY03XuXNn2bhxo/z6669ak8Oe2TWRo5LJiIhMg5k/24IFC3RG8PDhw65jKVOmFCfAoAnJfIkTJ47TPfOhTBxs3bq1/PLLL7J3714xmaOSyYiITNyNYt+eeOIJHWG7H5s/f76O2JIlSyYFCxbU3BrbiRMn9PuRa1OpUiXdvVK6dGk5cuSIbNu2TUqVKqWBHhUcL1686Pq5t99+W+rXr681IjJmzKg7X5DD417NDQVjUEcCS4a4XywXLlq0yKNvAh572bJlUrJkSd0dg0qPR48elVdffVVrVOCxcT6rVq3ymNX8448/NDcIP2/PKGDWoHjx4h7PzZgxY3T07X3egwcP1i14BQoUcLUdfvPNN7VASLp06fTx8dwE07hx46Rjx46SN29eMR0DNRFRkMyZM0dH2AhMBw8elCFDhkifPn1k5syZD02P9+7dW3bu3Kkj2qZNm2rS7NixY2X9+vXy+++/u3J3bNgBg/tEwJ03b5588803HsWdEKRnzZqlpZf379+vgfWtt96StWvXetxPjx49ZNiwYXpfRYsW1STfOnXq6P1jmbFWrVraPMnOF8Lj5MiRQz799FOdTXCfUYgO3C9mHJBrtHTpUt26hDwj9GXG74rpaFwg4HGjKiObMmXKKG+4cAkXnPomIgoSBGAkvb722mv6OUa3Bw4ckMmTJ0vLli1d39etWzdXUmyXLl2kSZMmGtCef/55PdamTZuHcnYwZTx9+nTdq/vss89q4OzevbsMHDhQgx8uCjAStrevYuSIETMeu0qVKq77wc9Vr17d9TlGtBh923B/ixcvlu+++046deqkX8eeYARWzBjEVIoUKTQJ2J7ynj17to7+ccwenc+YMUNH17gIqVGjhs/7edSaMmYZwgUDNRFRkLoDYhoZQbZdu3Ye1dcwRe4OI1mbXSa5SJEiHsfscpQ2BFP36m0IyBgNYxoZ/6LCm3sABoxQ7V02Nkyvu8PPYhobO2wwWsb5okSz+w4cf+D3cl+X3rNnj84YIPC7+/vvv/X5iwzaHMcXDNREREGAgAdTpkyRsmXLenzNu0oVOi3Z7FGl97GYNCmxHxvBNnv27B5f867UiBGuO4zuMS09cuRIDYZY327YsOEju5mhLrv3Lh6M7L15Px7OFWvkWCbwhvX3yDwqSQ/T/Jj2DwcM1EREQYBRMBKmUKSpWbNmAb9/jETdmxFt2bJFgxd6GWB6GgEZo2D3ae7owBoxkr4aNGjgCqTeiV0YEdvlXt2DKhonIVjbFxvR2fJUokQJzZZHPeyYTFfv5tQ3ERH5C8ld2K+LqW4kR6HlLgo9Xb161aNZUGxghItpdSShIZBiPRxryBjZYhoZI2MkkGEkXrFiRbl+/boGYQQw9/Vxb0899ZQmjCGBDAEXyW/eo3lkcq9bt04aN26sFwQZMmTQbHBkpg8fPlxH4MuXL9eM8kcFTFzEjBgxQjO9sV6ORDVkleMckFCXI0eOoEx9Y7odFyG4uMAFjx34CxUqZFyteWZ9ExEFSdu2bTVJCslRWJvF6BZJYUgq81fVqlU1qFauXFkaNWok9erV8yisgiQwBFlkf2N7GC4UMBX+qMcePXq0pE2bVipUqKDBGkluGPW6Q0DFxUG+fPlc09N4DGw9i4iI0PXzrVu36sXCo2CdHUE/V65cmnSH+8EFCNaogzkqbtu2ra7XI7kO2+HsKplnzpwR0ySwoioNFobQ5hJXt7i6DKepEXIYds/yCW/OqPmPYIJ9x+QbpqavXbsmS5YsCfWpUCxfzzGJRRxRExERGYyBmoiIyGBMJiMichhfDYsofHFETUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1EZEfUA87qpt7Wc9wgVrfY8aMESc7efKk1K1bV0uYoiEIenmjpWdUBg8erKVV8TPolx1XuI+aiJxdcjUojxf9Mq7o2WxDF6i+ffvK4cOHo92O0RSoJo2OWIkTx11YQGORUDTAuH//vgbpLFmyyKZNm/T/sEWLFtpadMiQIVGe7xtvvKG9v6dNmxZn58sRNRGRH/Bmb99QuxmjaPdj8+fP10YTqPVcsGBBbVxhQ2MLfP/ChQulUqVK2rKydOnS2iRi27ZtUqpUKQ30tWvX1s5U7rW+69evr9250BQDtaLbt2/v0TMaHa/QkAN1pnG/aJSxaNEi19fXrFmjj40OV+gHjS5YGzZskKNHj2onK7TpxGPjfFatWuX6OXTJQncrdOayZw0AMwfFixf3eG4w6sbo2/u8MTJFC9ACBQro8VOnTsmbb76po1S06MTje7fWDKSVK1fKgQMHZPbs2XrOeH7RxAQNRaLqu43nG783GqzEJQZqIqIgmTNnjo6wEZgOHjyoozV0tJo5c6bH96FFJdpV7ty5U0e0TZs21RaPY8eOlfXr12tLRtyPu9WrV+t9IuDOmzdP20IikNgQpGfNmiWTJk2S/fv3a4B56623ZO3atR7306NHDxk2bJjeV9GiRbX1Y506dfT+d+3apV230EULU8WAx0HrSXTQwkjUfUYhOnC/mHH46aefZOnSpXLv3j3t0IXWnPhd0YoTFwh43KiCZsqUKaO84cIlMps3b9Zgi4sRG84BjTLwXJmGU99EREGCADxq1Cht3wgY3WIkh9aK7j2h0Q4SgQK6dOkiTZo00YD2/PPP6zG0ffQuG4op4+nTp+t66bPPPquBE+usGBki+OGiACNhTNNC3rx5dcSMx0a7TRt+rnr16q7PMaLF6NuG+1u8eLF899132u8aX0+UKJEGVswYxFSKFCm09ac95Y1RLUb/OGaPztEWFKNrXITUqFHD5/3Y/aMjE1VHKvSgdg/SYH+Or5mGgZqIKAhu3ryp08gIsu3atXMdR8ISpsjdYSTrHTDcp1dx7MKFCx4/g2CKIG1DQMZoGNPI+PfWrVseARgwQkXPZXeYXneHn8U0NnpXY7SM8719+7ZrRO0v/F7u69J79uzRGQMEfu8WkXj+IpM/f36JLxioiYiCAAEPpkyZImXLlvX4Gkak7pDEZLNHld7HMOqM6WMj2GbPnt3ja1iL9h7husPoHtPSI0eO1GCI9e2GDRtGOQ0NCRMm1IQ0dxjZe/N+PJwr1sixTOAN6++ReVSSHqb5Me3vC2YCtm7d6nHs/Pnzrq+ZhoGaiCgIMApGwtSxY8ekWbNmAb9/jEQx0kUghS1btmjwypkzp05PIyBjFOw+zR0dWCNG0leDBg1cgdQ7sQsjYmROewdVTBsjWNsXG4+anoYSJUpotjy2SEU1XR3IqW/MPiBvALMUeFzAxQl+plChQmIaBmoioiBBclfnzp11qhvJUXfu3JHt27fL1atXpWvXrn7dN0a4mFZHEhoCKdbDsYaMkS2mkTEyRgIZRuIVK1aU69evaxBGMHJfH/f21FNPacIYEsgQcJH85j2aRyb3unXrpHHjxnpBkCFDBs0GR2b68OHDdQS+fPlyzSh/VPDFRcyIESM00xvr5UhUQ1Y5zgEJdTly5Aj41DfWvRGQmzdvrueLCww8jx07dnTNOGDEjS1byBWwZyVw4XPlyhX9Fxcq9sUCziWY2/BCnvWNdHj8p2PrAqaHvKcjvCHdHyn9uIrElSNeiFjLICIyTdu2bTVJCslRWJvF6BZJYUgq81fVqlU1qFauXFkaNWok9erV8yiugiQwBFlkf2N7GC4UMBX+qMcePXq0pE2bVgt7IFgjyQ2jXncIqLg4yJcvn2t6Go+BrWd4T8f6Od7LcbHwKFhnR9DPlSuXJt3hfnABgvf1mIywYwJLD8g4x78YXWOaHEEZv5cNa/zITnefvkfmPdb4cVGEmQZ8jBsuvoIpgeW9qBCHMN2BJwfrCAjSCMJff/21Pjn2dIS7uXPnSuvWrTXTES8i7DXEFA2u6vDiig6k3+PqFleXwXoREPlVwCMGxTbCDd6cjx8/rsEEF+/kG973rl27JkuWLAn1qVAsX88xiUUhHVEjuCIbslWrVjoNgYCNqysEYl9QQQbbFbDHEKNwTF9gG8OjRuFEREROFbJAjfWVHTt2SLVq1f7/ySRMqJ9jM7ovGEXjZ+zAjCSNH3/8UTfnExERhaOQJZNdunRJF+N9bTo/dOiQz5/BSBo/h8QIzNhjfx+qz/Tq1SvSx0HyBm7u0w1ERE7mXfyEwlvIk8liAlVqUG0HCQsotYesQCRHIGkiMkikwDqAfUMCGhERkVOEbESNdH5k3NmbzG34PLIN58hgRDo9MikBWZSo/vOvf/1LPvnkE50699azZ0+PbRAYUTNYExGRU4RsRI0N86hGgz1qNuzVw+d2bVpvSJf3DsZ2hZ/IktexJw4Zde43IiIipwhpwROMdLHxHrVmy5Qpo9uzMEJGFjhg6xY2mmP6GrCnD5ni2LeG7VyoD4tRNo57l+QjIiIKByEN1Nikj0o22ESOyjDoC4pqNnaCGaq/uI+gUTkGlXLw7+nTp3WjPYI0SsERERGFo5AWPAkFFjwhI7DgiU8seELh5O9wKHhCREREUWOgJiLyA5bjorq5198OF6gMiZwiJ0vg4/9q/vz5YiJ2zyIi4xWZWSROH29fy33R/t6zZ8969C9Azg36FdiC2VUpkLAKiiJUiRMnjtMKldgBFCozZszQZiW2NGnSiIk4oiYi8gPqPtg3rDliZOZ+DKM0dITCGmXBggW1YJMNHajw/QsXLpRKlSppV8DSpUtrw6Ft27bpjhgE+tq1a2virXtTjvr162sbTSTVYo0TVRoR+Ny3u2LHDNZHcb/oaLVo0SKPAlJ4bLSixFZZbGXdsGGDHD16VFtOIqkXj43zWbVqlevn0M4SbSjRudAeiQJmDpAQ7A6jboy+vc8bCcDo1Y1OiHDq1Cl58803NVCilzYe37sHdjDg8dz/r0zNi2CgJiIKkjlz5ugIG4Hp4MGDWlkRW0pnzpzp8X1om4jdLKi4iBEtyiWjF/PYsWNl/fr1uhUV9+MONSdwnwi48+bN00qNCNw2BOlZs2Zps6P9+/drYEU7x7Vr13rcT48ePWTYsGF6X0WLFtX2jeifgPvftWuXjjixuwa7cACPgx7RaAmJ2QT3GYXowP1ixuGnn37SVpNoI4lWmuihjd8VPbNxgYDHdb/w8IbvieqGC5dHQf9pFN/C9mA0gzI1t5pT30REQYIAPGrUKO2zDBjdHjhwQCZPnqw1JGzo24xgBV26dNGugAho6BYI6M/sXd8bU8YILug4+Oyzz2rg7N69u5ZURvDDRQFGwnYBqbx58+qIGY+Nvtg2/Fz16tVdn2NEi9G3Dfe3ePFi+e6776RTp076ddStQGCNrIpkVFKkSKE9uu0p79mzZ+voH8fs0TmmpDHaxUVIjRo1fN7P7t27o3ycR2VS4/d+6aWX9PlbuXKldOjQQS9SOnfuLKZhoCYiCgIUb8I0MoIs2vna0EwIU+TuMJK12XUkUCLZ/diFCxc8fgbBFEHGhoCMQINpZPyLSo7uARgwQkXBKHeYXneHn8U0NvooYLSM8719+7ZrRO0v/F7u69J79uzRGQMEfu+tTXj+IpM/f37xB2Y2bHhO8P81YsQIBmoiovgCAQ+mTJmilRTdeVdSTJIkietje1TpfQyjzpg+NoItqju6w1q09wjXHUb3mJYeOXKkBkOsbzds2DDKaWhAcSrvqWOM7L15Px7OFWvkWCbwhvX3yDwqSQ/T/Jj2jy78H2H2AN0WvZ+jUGOgJiIKAoyCkTB17NgxadasWcDvHyNRjHQRSGHLli0avNB0CNPTCDYYBbtPc0cH1oiR9NWgQQNXIPVO7MKIGBni3kEVFSYRrO2LjUdNT0OJEiU0Wz5TpkwxKkK128+pb1/3lzZtWuOCNDBQExEFCZK7MJWKqW4kR2G0tn37drl69apHV7/YwAgX0+pIQkMgxXo41pAxssU0MkbGSCDDSLxixYpaAQtBGAHMfX3c21NPPaUJY0ggQ8DFFLH3aB6Z3OvWrZPGjRtrYENCFrLBkZk+fPhwHYGjHDQyyh8VMHERgylnZHpj3RiJasgqxzkgoS5HjhwBn/r+/vvvtVNjuXLlNNMbMwhY08dzZiJmfRMRBQla8iJJCslRWJvF6BZJYUgq81fVqlU1qFauXFn7JtSrV8+juAqmcRFkkf2N7WG4UMBU+KMeG42PMLKsUKGCBmskuWHU6w4BFRcH+fLlc01P4zGw9SwiIkLXz7du3RqtwId1dgT9XLlyadId7gcXIFijDlaZ5yRJkuh5Yl0fW8qQYIffGxc7JmKtb6JQYK1vn1jrO3owNX3t2jVZsmRJqE+FosBa30RERPEAAzUREZHBmExGROQw3sVPKLzFakT9888/B/5MiIiIKDCBGtmDyPYbNGiQVsEhIiIigwL16dOndb8eOrGgfizS99H95VGVa4iIoiOebUahMGUF6HUcq0CNze3YSI9KLr/88os8/fTTWtAcVXiwuR8Vc4iIYsourcmLfgoHt27deqgcbEiSybARHh1U0qdPr63S0M0Fm96xkRx1VtHVhYgoOtDiEQUwUOEKb26oskXkxJE0gjQaqaALmHdt9zgL1Ci2/u2332pgRvk1dGAZP368tmfDHxnK2r3xxhva0o2IKDpQsjJr1qxaJAJlJImcDEE6Nq1AAxKo33vvPW1UjquG5s2ba23XwoULe3RHQecVTIUTEcUEGj6gNCanv8nJkiRJ4vdI2q9AjVHyv//9b63LGlmnEaxjcxsXEcUGprxZQpTo/8RqAQiFyzGt7R2k0WAcxdXttaaYtlcjIiKiAATqF198Ua5cufLQcRQXx9eIiIgohIHavTG4u8uXL+v6NBEREUncr1FjTRoQpNFmzX3q+/79+7J3717tYUpEREQhCNTonWmPqFOlSiWPP/64R6ZmuXLlpF27dgE6NSIiIopRoJ4xY4b+mzt3bunWrRunuYmIiEzN+g5UkI6IiNDAj60YZcuWla1bt0b5/deuXZOOHTtqUQRMvaN86Y8//hiQcyEiInLsiBqlQlevXi1p06aV5557zmcymW3nzp3Rus8FCxZI165dtdQogvSYMWO0wcfhw4clU6ZMD30/CiBUr15dv4aGINmzZ9fqRaj+QkREFK8D9auvvupKHqtfv35AHnz06NG6pt2qVSv9HAH7hx9+0LKkPXr0eOj7cRzbwjZt2uQqco7ROBERUbhKYIWonxxGxyi+j5Gxe+Bv2bKlTm+jjri3OnXqSLp06fTn8PWMGTNK06ZN5eOPP460VNudO3f0Zrtx44bkzJlT93ynTp06SL8d0SP0fyKKr12PyzMhohBALEKCdnRiUcha01y6dEm3dGXOnNnjOD4/d+6cz585duyYBnb8HNal+/TpI6NGjZJBgwZF+jhDhw7VJ8O+IUgTERGF3dQ31qajWpd256tqWSA8ePBA16e/+OILHUGXLFlSTp8+LSNGjNAEN1969uyp6+DeI2oiIqKwCtRI9AokNO1AsD1//rzHcXweWVswZHp7dyR55plndASOqXTs5faGdfXIGocQERGFTaDG2nEgIahiRIxMcnuNGiNmfN6pUyefP/P888/L3Llz9fvshvJHjhzRAO4rSBMRETldtNeoMWXs/nFUt+jClPSUKVNk5syZcvDgQXn33Xfl5s2brizwFi1a6NS1DV/HtHqXLl00QCNDfMiQIbqvmoiISOL7GvXZs2d1jRj7ln2tV9vNOpDsFR2NGjWSixcvSt++fXX6unjx4rJ8+XJXgtnJkyddI2fA2vKKFSvkgw8+kKJFi+o+agRtZH0TERHF6+1Za9eu1aln9JnGx1ExuQ91TFLiifyRu8cPkX7tRLKmkf8gt2cRhb0bMYhF0R5RuwdfkwMxERFRvG3K4e7q1asybdo0XVuGQoUK6doyCpIQERFRYMSq4Mm6deu0dOe4ceM0YOOGj/PkyaNfIyIiohCOqJFljUSwiRMnuvY0I4GsQ4cO+rV9+/YF6PSIiIjit1iNqH///Xf58MMPPQqP4GNst8LXiIiIKISBGi0v7bVpdzhWrFixQJwXERERxWTqe+/eva6PO3furPuXMXouV66cHtuyZYtERETIsGHDgnOmRERE8VC091Gj8AiKmTzq22NS8CQUuI+a4gr3URNRnO6jPn78eHS/lYiIiAIk2oH6ySefDNRjEhERUbALnsCBAwe0HjdaTLqrV6+eP3dLRERE/gTqY8eOSYMGDXS/tPu6td2ow+Q1aiIiorDfnoWMb1Qhu3DhgiRPnlz279+vFclKlSola9asCfxZEhERxVOxGlFv3rxZ/vvf/0qGDBk0Gxy3ihUrytChQ3Xr1q5duwJ/pkRERPFQrEbUmNpOlSqVfoxgfebMGVfC2eHDhwN7hkRERPFYrEbUhQsXlj179uj0d9myZWX48OHy2GOPyRdffCF58+YN/FkSERHFU7EK1L1795abN2/qx59++qm8/PLLUqlSJUmfPr0sWLAg0OdIREQUb8UqUNesWdP1cf78+eXQoUNy5coVSZs2rSvzm4iIiEK8jxpOnTql/+bMmTMAp0NERER+J5P9888/0qdPH61Tmjt3br3hY0yJ37t3LzZ3SURERIEaUb/33nvyzTffaBJZ+fLlXVu2+vfvL5cvX5aJEyfG5m6JiIgoEIF67ty5Mn/+fKldu7brWNGiRXX6u0mTJgzUREREoZz6Tpo0qU53e8N2LWzTIiIiohAG6k6dOsnAgQPlzp07rmP4ePDgwfo1IiIiiuOp79dee83j81WrVkmOHDmkWLFi+jkKoKCLVtWqVQN0akRERBTtQI2sbnevv/66x+fcnkVERBTCQD1jxowgPDwREREFreDJxYsXXU04ChQoIBkzZvTn7oiIiCgQyWSo8926dWvJmjWrVK5cWW/ZsmWTNm3ayK1bt2Jzl0RERBSoQN21a1dZu3atfP/993Lt2jW9ffvtt3rsww8/jPH9RURE6HavZMmSaTeurVu3RuvnsJcbtcXr168fi9+CiIgoTAP1f/7zH5k2bZoWPEmdOrXe6tSpI1OmTJFFixbF6L7QbQuBv1+/frJz507NIkfTjwsXLkT5cydOnJBu3bpp1y4iIqJwFatAjentzJkzP3Q8U6ZMMZ76Hj16tLRr105atWolhQoVkkmTJkny5Mll+vTpkf7M/fv3pVmzZjJgwAD2vyYiorAWq0CN+t4YAf/999+uY7dv39bAadf+jg7su96xY4dUq1bt/59QwoT6OWqHRwY9sHFRgDXxR0Ehlhs3bnjciIiIwjrre8yYMVKrVq2HCp5gjXnFihXRvp9Lly7p6Nh7dI7P0ePalw0bNui0++7du6P1GEOHDtULCCIiongTqIsUKSK//fabzJkzxxVQ0YwD09GPP/64BMuff/4pzZs317XwDBkyROtnevbsqWvgNoyoWZyFiIjCNlCj33TBggVl6dKlurbsDwTbRIkSyfnz5z2O4/MsWbI89P1Hjx7VJLJXXnnFdezBgwf6b+LEiXVPd758+R5qIIIbERFRvFijTpIkicfatD/QaatkyZKyevVqj8CLz32tdeMCYd++fTrtbd/q1asnL774on7MkTIREYWbWE19d+zYUT777DOZOnWqjmT9gWnpli1bSqlSpaRMmTK6/o2CKsgChxYtWkj27Nl1rRlr4IULF/b4+TRp0ui/3seJiIjCQayi7LZt23TUu3LlSl2vTpEihcfXv/nmm2jfV6NGjbQUad++feXcuXNSvHhxWb58uSvB7OTJk5oJTkREFB/FKlBjFOvdPcsf6GEdWR/rNWvWRPmzX375ZcDOg4iIyNGBGuvHI0aMkCNHjuge6Jdeekn69+8f1ExvIiKi+CxGc8qDBw+WXr16ScqUKXXdeNy4cbpeTURERAaMqGfNmiUTJkyQd955Rz9ftWqV1K1bV5PKuI5MRBTecvf4wefxE8Pqxvm5xCcxiq5I7ELzDRtKfaJ71ZkzZ4JxbkRERPFejAL1P//8o1ukvPdVowgKERERhXjq27Isefvttz0qfaH4Sfv27T22aMVkexYREREFKFCjMIm3t956KyZ3QURERMEK1DNmzIjJtxMREZGfmKpNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBGKiJiIgMxkBNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBGKiJiIgMxkBNRERksMShPgEi8lRkZpFIv7av5b44PRciCj2OqImIiAzGQE1ERGQwIwJ1RESE5M6dW5IlSyZly5aVrVu3Rvq9U6ZMkUqVKknatGn1Vq1atSi/n4iIyMlCvka9YMEC6dq1q0yaNEmD9JgxY6RmzZpy+PBhyZQp00Pfv2bNGmnSpIlUqFBBA/tnn30mNWrUkP3790v27NlD8jsQEZFvzLkIgxH16NGjpV27dtKqVSspVKiQBuzkyZPL9OnTfX7/nDlzpEOHDlK8eHEpWLCgTJ06VR48eCCrV6+O83MnIiIK60B99+5d2bFjh05fu04oYUL9fPPmzdG6j1u3bsm9e/ckXbp0QTxTIiKieDj1fenSJbl//75kzpzZ4zg+P3ToULTu4+OPP5Zs2bJ5BHt3d+7c0Zvtxo0bfp41ERFRPJr69sewYcNk/vz5snjxYl2v9mXo0KHyxBNPuG45c+aM8/MkIiJyZKDOkCGDJEqUSM6fP+9xHJ9nyZIlyp8dOXKkBuqVK1dK0aJFI/2+nj17yvXr1123U6dOBez8iYiIwjpQP/bYY1KyZEmPRDA7Max8+fKR/tzw4cNl4MCBsnz5cilVqlSUj5E0aVJJnTq1x42IiMgpQr49C1uzWrZsqQG3TJkyuj3r5s2bmgUOLVq00G1XmMIGbMfq27evzJ07V/denzt3To+nTJlSb0REROEk5IG6UaNGcvHiRQ2+CLrYdoWRsp1gdvLkSc0Et02cOFGzxRs2bOhxP/369ZP+/fvH+fkTERGFdaCGTp066c0XFDhxd+LEiTg6KyIiotBzdNY3ERFRuGOgJiIiMhgDNRERkcGMWKOOj1ionoiIooMjaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1ERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY1MOIvIbm8xQOCli2OuZI2oiIiKDMVATEREZjFPf5NjpICKi+IAjaiIiIoMxUBMRERmMU99+yt3jh0i/dmJY3Tg9FyIiCj8cURMRERmMgZqIiMhgnPqmsMZMdQqn14YTz5n8xxE1ERGRwRioiYiIDMZATUREZDAjAnVERITkzp1bkiVLJmXLlpWtW7dG+f1ff/21FCxYUL+/SJEi8uOPP8bZuRIREcWrQL1gwQLp2rWr9OvXT3bu3CnFihWTmjVryoULF3x+/6ZNm6RJkybSpk0b2bVrl9SvX19vv/76a5yfOxERUdgH6tGjR0u7du2kVatWUqhQIZk0aZIkT55cpk+f7vP7x44dK7Vq1ZLu3bvLM888IwMHDpQSJUrI+PHj4/zciYiIwnp71t27d2XHjh3Ss2dP17GECRNKtWrVZPPmzT5/BscxAneHEfiSJUuCfr5ERORD/yci/1qeXHF5JmEppIH60qVLcv/+fcmcObPHcXx+6NAhnz9z7tw5n9+P477cuXNHb7br16/rvzdu3AjAbyDy4M6tSL8W1WPcv30/Vj8XCIX7rYj0a78OqGnkOcdWKM85ytdGAsvY5zmy1wdfG6EX6nOO7DXN13PM2fdjWZE/dy5WCJ0+fRpnaG3atMnjePfu3a0yZcr4/JkkSZJYc+fO9TgWERFhZcqUyef39+vXTx+DN95444033sSw26lTpx4ZK0M6os6QIYMkSpRIzp8/73Ecn2fJksXnz+B4TL4f0+ruU+UPHjyQK1euSPr06SVBggQSSLhCypkzp5w6dUpSp04tTsBzjhs857jBc44bPGf/YST9559/SrZs2R75vSEN1I899piULFlSVq9erZnbdiDF5506dfL5M+XLl9evv//++65jP/30kx73JWnSpHpzlyZNGgkmvAhMeCHEBM85bvCc4wbPOW7wnP3zxBNRrO2bVOsbo92WLVtKqVKlpEyZMjJmzBi5efOmZoFDixYtJHv27DJ06FD9vEuXLlKlShUZNWqU1K1bV+bPny/bt2+XL774IsS/CRERUeCFPFA3atRILl68KH379tWEsOLFi8vy5ctdCWMnT57UTHBbhQoVZO7cudK7d2/p1auXPPXUU5rxXbhw4RD+FkRERGEaqAHT3JFNda9Zs+ahY2+88YbeTIMpdhRu8Z5qNxnPOW7wnOMGzzlu8JzjVgJklMXxYxIREZFTKpMRERFR5BioiYiIDMZATUREZDAGaiIiIoMxUMfSP//8I7NmzXqoShoREVEgMevbD2jHefDgQXnyySfFKVBcBr28K1euLE6SN29e2bZtm5Z+dXft2jVtc3rs2DEJte+++y7a31uvXr2gnkt8hkY/+/bt07/LtGnThvp0HCsmzSdMqfTlbd26dRIVp7wPGrGP2qlQSW337t2OCtToHoY2ojhnVH9D4EblN9OdOHFC34C9oTPa6dOnxQR2GVwbasm7Xwe715b39buYYObMmVqDH1X/4KOPPtKqf+gVP2/ePCNf6ygnXKRIEb0AxfOKyoWbNm3SC+mlS5fKCy+8EOpTdCSUWo5uPwRTX88v+Pi/d8LfoTcGaj906NBBS6CiyDtqlqdIkcLj60WLFhXToIobKsF99dVX+qaMAgAI3HiTe/XVVyVJkiRiEvdR6ooVKzxq4+KPDHXfc+fOLSZAnXrbqlWr5OOPP5YhQ4a46tCjlzoq6uGYqXBuEydOdJ1vRESEfP755xrwPvjgA/nmm2/ENIsWLZK33npLP/7+++/l+PHj2iYXr/FPPvlENm7cKCbCeS9cuFCrL969e9fjazt37pRQ+/nnnz0ulHv06CFvv/22x+sZ7yF2eWcTXb161ePze/fuya5du6RPnz4yePBgcYwYdKUkLwkSJHjoljBhQte/TrBjxw6rU6dOVrJkyawMGTJY77//vnXkyBHL5OfYvj322GPW008/bX3//feWaZ599llr/fr1Dx1ft26dVbBgQctUjz/+uPXHH3/oxx999JHVvHlz/fjXX3/V14eJkiZN6moV2K5dO6tLly768bFjx6xUqVJZJho7dqyVMmVK/dvD6/idd96xqlWrZj3xxBNWr169LNO89NJLD7UXhjlz5lhVqlSxnGbNmjVWiRIlLKdgMpkfcOXufcNaqf2v6c6ePaudx3BDu9E6dero2h6mOTGKMmWUihumXDETYH+OG6a9Dx8+LC+//LKY5ujRoz67tGFGAKMTU6VMmVIuX76sH69cuVKqV6+uHydLlkxu374tJkJfgAMHDugMC/oE2Od869YtfV2baMKECbqk8O9//1u7CGKJAX+HnTt31uUp02D0jMZJ3nBs69at4jSZM2fW9w7HCPWVAsWtu3fvWosWLbLq1q1rJUmSxCpZsqQ1ceJE6/r1667v+eabb6w0adJYJp0zruhNGuk/SqVKlazq1atb586dcx3DxzVq1LAqV65smapp06Y60mjTpo2VPHly69KlS3r822+/1VkCE/Xr109HopipyJUrl/X333/r8WnTplnlypWzTJ25OHHihH6cMWNGa/fu3foxXuPp0qWzTIOZq+7duz90HMfwNVPt2bPH44bnedmyZToL8Pzzz1tOwTVqP2EdbNKkSTqKxlUnRn5o1ZknTx5d8zVN1qxZdTTapEkTvRJGtzJvL774YtB7dscE1s337t0rTjJt2jR57bXXJFeuXNqsHpDLYHd7MxXWpLGOjnP9z3/+48qy37Fjh75mTNS/f3/tnodzRrMeu+kCRtNYVzVRlixZ5MqVK/p+gdfIli1bpFixYvo+YuJGHMywvf7667Js2TIpW7asHsP7x2+//aavE1MVL178oaROKFeunEyfPl2cgtuz/ICkG7TnRNYpEhN+/fVX3Ub05ZdfapKFezKGSRcWeDPDVKaTIJEJb8DDhg0Tp8CfFqYzkdgEzzzzjCbuRTeTlmLu77//dsRru23btnoBh2ROXBx1795dnn/+edm+fbte4OFCzzT/+9//9D0PW1Lt13P79u1dF6Im+uOPPzw+R8vkjBkzOuI14o6B2g9Yy0WWLLblpEqVSvbs2aOBGgEb2wIuXbokJkHG4+OPP65bypzWv/u9997TAjMYkfrKsB89erSYwsnPM6xfv14mT56seRZff/21bt/DBR5miSpWrCimwdo0/g4xs4UCREeOHNG/Q2T2YkcAdjSYxs6zSJz4/yY158+fr1vK8Pp+5513dN3apNdzrVq19PnF+VHcYzKZHzBN9dxzzz10HCO/mzdvimkwhYxpNqfsHXSHix8UNsEFEd6IscXCviEgmsTJzzOmMWvWrKkXGtgihIQ9QIKTqdvKMJuFWazhw4d7BDhcJE2dOlVMhJGdHaShcePGMm7cOL0gNSlIO3Xpyd3atWvllVdekfz58+sNxYZwMeoooV4kd7JnnnnGWrJkiX6MrRZHjx7Vj8eNG2c999xzlommTp1q1alTx7p8+XKoTyWsOfV5Ll68uDVz5syHXtM7d+60MmfObJkoX7581qpVqx4654MHDxqVFOkuT5481ttvv+1KfLNdvHhRv2YabNv8+OOPLaf56quvrMSJE1tvvvmmbonDDR8jkRZby5yCyWR+QLGTjh076roYVhCQXIHqTSgAYOqV/Pjx4+X333+XbNmyaSKL9xSyCYUWorNWBjly5BBTOfV5xpYVX2UVsa0M5VpNhMp0GCl5w9Qypm1NhC16GFFXqlRJi/oguQwwC+O9rmpKbwMkX6GQj+lLT96zLZhpQY6LDVvgcL4DBw6Upk2bihMwUPuZEIIpQmTJYs8m/tPxxjx27FidyjKRd5lLp8Cb7qBBg2TUqFHy119/6TFMg3/44YdafQpTiSZx6vOMgIELDO9qbxs2bNB1X1NzRTCV6V3eFJW/fC1NmQAJhdjz3a1bNw182AlQunRpMX3pCbD05M7k5Mhjx47ptLc3TH/36tVLHCPUQ/pwcfPmTev8+fOhPo2w1aNHD91vOmHCBNeeyIiICD1mYiUnpxoyZIhVqFAha8uWLVrVC9XVZs+erc8zlnRMhOUn7KMeNmyY7v0eMWKE1bZtW634tXLlSstEqKxnv1/gtY191ZimxV57p1Q1dIJ8+fJZkyZNeug4akfkz5/fcgoGaj/cunVLA7QNBQw+//xza8WKFZbJrl69ak2ZMkXfIOw1VJQS/d///meZKmvWrFp0w9ebdLZs2UJyTuHowYMH1qBBg6wUKVK4SrWivGzv3r0tk6E0K0pw4oICQQ/FLEz+O0Qwdr+wR5DG89yqVSsG6gCaMGGCXrC1b9/emjVrlt5QrhVlZ30FcFNxe5YfatSooXsesZcQ63cFChTQjE1sy8IayLvvviumQfYm9vLapSyxJokpTUzfozkAtkCZCPsece5PP/20x3GcP4oamFbeEmuNKBIRWdMFFLswGc4XU+BYZsDUMkqLUuBgqebcuXOSKVMm1zEUTGrQoIGWyjVxxwD2eEf2ejaxWYtt8eLFumTmvv8b+9ZNLEgVqVBfKThZ+vTptVkBYIRatGhR6/79+9bChQuNbbxQtWpVVylA9wzZjRs3Wk8++aRlqjJlyljvvffeQ8fR1KBs2bKWafr06aOzACNHjtSR0sCBA7UsJ14zyDylwMHz+vPPP1vhAFPfaBhhmnnz5mmm9Msvv6wjVPyL0qFYckD2uqlatGhhrV271nI6BuoAdRp64403rP79++vHJ0+e1K+ZKHXq1Nbvv//+UKDGtD2mg0yFNy9Mx2JLXOvWrfWGj/E7YNrTNHnz5rWWLl2qH+Mc7eccQbpJkyaWqf766y+d5i5fvryu72GrkPvNRPXq1dPXbo4cOaxu3bpZu3btskw3YMAAa/Xq1T6ff3zNNEWKFLHGjx/v8b6BZRJ0K+vbt69lqldffVUvMLAePXjwYOv06dOWEzFQ+/nixRsvAjMC4KZNm/T49u3bjd1zijU87In1DtRIusEbncnwR4bEsddee01vn3zyibF/eEhqsi/ismTJojkAgOcbrxVTNW7cWGcC0OIS+RZjxozxuJnqypUr1uTJk7XZAtZ4kRCHN+bjx49bJrLbtI4aNcrjuKnJZHg9288lmobs3btXPz5w4IC+vk124cIFfZ4x44k91bVq1dJZTzT7cQoGaj98/fXXerWGPywksrhnzuLFYOo0Yf369fVFikCNnr0IKCjQYvfxNUWDBg1cXb1QhMO7OITJMC2IzGlAYtPQoUP14/nz5+vFkqkwlblhwwbLydCbevjw4br8lChRIsvUQI3XApZCMHV8584dowN19uzZXcEZAxS7NzUGJyZfeHrDBTOWy7Achf7qKOTihK58DNR+Onv2rI5QsTZt++WXX7QqkomuXbumFxWo2IQ3sZw5c+rFBlovYtrNJDivM2fO+MySNR2qOGFEB3hDxpU8pt8wijK5wlPu3Ll1lORUuABdvHix9frrr+ubsak7AuztWVgSwRIOlhrwuamBGss19uj/008/1YtNbIFDXgsuqJ3gzJkzuoWvQIECuoyG9Wvk7OBvc/To0ZbJmPUdj6pleRewQBY1snpRyACZ4KYpWrSonhvabrZq1UprIadOndrn97Zo0UJMhjaGdtMFXwUYTDF79mz59ttvtftb8uTJxSnQqW7u3LlaqxzFcbAbo1mzZvLSSy8ZWZADLTjPnj2rWd83btyQN998U/bv36+NL1CMw7Ssb+xSQAVGFHTC84tqX/brGTtG0qZNKya6d++eVn6bMWOGrFy5Ut9TUKgKxans9xJkhbdu3VquXr0qpmKgjkfVsgA9e01uS+du48aN+lwePXpU3yjw3Pp608Ux07c7mQzVu9yfV2zLwtsCqpOhIYPppU/R3Qv//+jwhOCMCyG7J7VTtmfhvQTtctFGEh+bFqidKkOGDPp8opd6u3btdCunN2ytxd8AmiyZiiVE/YBgjL6x6JGMXrL2SBWN7HH1iTqzpsGbL1oVvvXWW9KwYUNjr4QBzylGovYbG0oXuu87NRm6Z6HVaZUqVfTffPnyiamcWu7Uhr839FhPkyaNOAVGeKhlYMPrGzNGCBjr1q0T02DGCjNbqANv8mvZG2oZ4LURVf9pvG5MDtLAEbUfMA1kT1W5w9Rhhw4dtFmAadAWElOE6H+LwgoYhSBomzgKwfQl2hdiigpTsZgeRG11J8AUMt5w16xZoyNUjPoQtO3Azb6+weG0JSinwHQxXs/ur2X7QpSv5eBjoI5H1bLc4b8dQcR7XQ8dckyBKm/oJJQ1a1aPNT2nwXmjJ+7SpUtlwYIFRk9tbtu2Tc+vbNmyHsd/+eUX/T8oVaqUmMYpS1AYMf/rX//S9w18HBksQ6AvtYkw+EDAxusZN8xy4e/TvkCi4GCg9gPezHDz/qPDHxne8OxpW9Nh3bFNmzZ60WFSAHF6Mhk6qmEpBBdESHbCbAbKF2Ikgik5E5UpU0Y++ugjXRbxLhH52WefacA2Tc+ePXUJasCAAQ8tQWFd0pQlqDx58mgZzvTp0+vHUQVqdH0ykf2axusZr2u8d6DELF7bFDwM1H7AFWXdunV1PbJ8+fKuer1I2Prxxx+116ypcAWM0TRuaGGH80ciDuqWmwJZpej57cRksgoVKngEZkwRYn3P5JwAQE1vXLB5t7TEGh4unP78808xjROXoNzZb8EmZqfb0BISgdl+TdtT3054TYcDBmo/nTlzRiIiIuTQoUP6OV7EeHPAm4eJJk+erMEZV8U4VwRnbFXw7uXrhCYGJkuXLp2eMxq34A0NN+8lEhNhtIcpevvC0/2iCRelJm5hceoSFGYBMLPy22+/6edY60XmN9aDTYPXcsaMGeWDDz7QJTInvJbDCQN1PIOtWdiqgABdrFgxcQqsVaNrDy40MC349ddfa1LLV199pdOIyGQ3Cf6s9u3bp6MQzLxgXQ9r7hiJYCofU7ImwmsDa+oYjdpZydi+gsxwXCShe5JpnLgE1bdvX+2wh3N0n40bP368BsNPP/1UTLJnzx59HeP1vH79etdr2UkXoU7GQB1DuHKPLkwVmgb/3RhNOyXg2ZDw1rx5c73AwLkeOHBAp2fxxoZlBtxMhed8x44deq5z5swxOpkM08SYzrx8+bJuFYLdu3dL5syZ5aeffjJyD35kS1C4sFu2bJmRS1AYneLCAhdG7ubNm6fBG61yTYbAjdkA01/P4YL7qGMIU2lYS3rU9Q2+x8QXL5KC7ICHRJA7d+7o8evXr8uQIUOMDXjI6sU6JJLGsLXMhuQhfM00eG4x+sANF0ZY2y1SpIi+CWMkYipctOFiFG/AeDPGdjgk8iGgeBc/MQWeT0xzo1iI3XMY07MmL0GhYpavDPqSJUvKP//8I6bB+x3Wp91f06iohsGIya/ncMERdSymYKPLxHVfjJIwtYaAh+QsvBljZIo/wtq1a+s6sIlQzhKjaBRscT9vzAog6xQFZkySOHFifa7tvdMYpboXuKDAwv8/LjAuXLigIzx33klmJsAFGy58MP3trlu3brqmjrwXkyBhDFvfsFxmT3ljpsJJRWacjCPqGHIPvkOHDtUpQdSJdYe9yCgm8vHHH4tpMPJA0PCGIIK1SFNlyZJFiy0gULvDlb13hnKoYSYFMxd4I3NiRiySm7D9xlfQw9qqaZYvX64Xnpiu9x53mDqzZSeTof50uXLl9HNsfcN0PX4X7HaweQfzUBXwwes5su2RFFwM1AHIoPb27LPPSuPGjY0M1E4KeO6QfNWlSxe9CMKbL7LtsQ6JEUifPn3EJCgMgipqmIZ1WqCeMmWKvPvuu1ojGa8V9y1D+NjEQI3RKcpE4txw4ewE2BKJGgGA7YeA5xw3fM1mypYt5ADYWP0tBELWtysMJE2aVPs5ezt69Kh+zUTolV2oUCHtlZwqVSpr/fr11uzZs7Vt3bhx4yxTPXjwwBo0aJC2p0OLQNzQxrB3796WiUqWLGmtWrXKcppcuXJpK0AnwesY7SIpeNDGd8CAAdp7Gm04cUPvcrS8dG/xS8HBQO0H9Bf+6quvHjo+a9YsK0+ePJaJnBbwvN25c8fav3+/9vz+888/LVMtW7bMKl68uPX9999rH9zr16973EwOerjQdJJWrVpZU6dODfVphLUePXroxfyECROsPXv26C0iIkKP9erVK9SnF/aYTOYH9GTFbcSIEdr3FlavXq0lGFFnGKUNTXX37l2dAkeCCJKxUJGKAse9vrT79CX+3ExeN0Up2dKlSxtVoS46ZS0x9Y0tT8is985O79y5c8jOLVw4vfqb03GN2g/du3fXBBa8UBH47CpJWJs2OUgDChYgQFNwIBnLifLnz69r/igS4pSgh73HSMrC3x62Dnmvq5t4zk6DEr0FCxZ86DiOmVa+NxxxRB0AGJUicQh7TlEG0LR2kUTR5cRmEUh6QzDu0aOHMZ2ywo0Tq7+FEwZqoiDBdjdswbGLcGA3ALbycT914OuqI1jky5cv1KcStpzcgCgcMFATBQHaGdasWVNnWdA6EhBMUMwC07T21hwTYM/uwIEDJUWKFB77d32NqNHz2TQo4IP1aXR4ouDA/m4U8fHVgAiV1BDAKXgYqImCACMMrPdiXzLe4ABvaOiMhOljNOkwBZqELF68WKtM4eOoAvV///tfMQ2mvWfNmqVVs1DS0ntd3YSCIU6H2gBo1uLdvQ45OjhmanJkuGCgJgoCjKRRltU7AQdlUFHjGZnKFBhOvLhwmsjazKKkMpJSb968GbJziw+Y9U0UBCi1iOlC70CNNT3UKqfAcWqGvRPYSyF2VTrU3LdhFI2yp2hURMHFQE0UBI0aNdI9ySNHjpQKFSrosY0bN+qWPu/WhkSmwqyQe391bOu04WMsN6CMLwUXp76JAgTdmwoXLqzThNhXj6CMIhF220KsnaKO9rBhw7iFjxwFrU7Hjh3LphwhwkBNFISEGzQ4QZY31qrtpgvYPuQ+dUhEFB2c+iYKEGRNHz9+XAP1iRMntEUkAjMqfBERxRYDNVGAvP7661KlShXJmjWrJt8guxujbF9MrPBFRGZioCYKkC+++EJee+01bXaCvb3ooc0MbyLyF9eoiYKUfIO6yAzUROQvBmoiIiKDsdUMERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiISc/0/OI2lmqys7RMAAAAASUVORK5CYII=",
                  "text/plain": [
                     "<Figure size 500x300 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# temperature scaling = scale the softmax to control the width of the distribution\n",
            "# dividing the logits with the temp values > 1, result in a flatter more spreadout distribution\n",
            "# temp values < 1 result in a peakier distribution \n",
            "def softmax_with_temperature(logits, temperature):\n",
            "    scaled_logits = logits / temperature\n",
            "    return torch.softmax(scaled_logits, dim=0)\n",
            "\n",
            "temperatures = [1, 0.1, 5]\n",
            "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
            "x = torch.arange(len(vocab))\n",
            "bar_width = 0.15\n",
            "fig, ax = plt.subplots(figsize=(5, 3))\n",
            "for i, T in enumerate(temperatures):\n",
            "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
            "    bar_width, label=f'Temperature = {T}')\n",
            "    ax.set_ylabel('Probability')\n",
            "    ax.set_xticks(x)\n",
            "    ax.set_xticklabels(vocab.keys(), rotation=90)\n",
            "ax.legend()\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 149,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "temp :1\n",
                  "73 x closer\n",
                  "0 x every\n",
                  "0 x effort\n",
                  "582 x forward\n",
                  "2 x inches\n",
                  "0 x moves\n",
                  "0 x pizza\n",
                  "343 x toward\n",
                  "temp :0.1\n",
                  "0 x closer\n",
                  "0 x every\n",
                  "0 x effort\n",
                  "985 x forward\n",
                  "0 x inches\n",
                  "0 x moves\n",
                  "0 x pizza\n",
                  "15 x toward\n",
                  "temp :5\n",
                  "165 x closer\n",
                  "75 x every\n",
                  "42 x effort\n",
                  "239 x forward\n",
                  "71 x inches\n",
                  "46 x moves\n",
                  "32 x pizza\n",
                  "227 x toward\n",
                  "103 x you\n",
                  "temp :1\n",
                  "temp :0.1\n",
                  "temp :5\n",
                  "tensor(0.0430)\n"
               ]
            }
         ],
         "source": [
            "# exercise 5.1 \n",
            "#Use the print_sampled_tokens function to print the sampling\n",
            "#frequencies of the softmax probabilities scaled with the\n",
            "# temperatures shown in figure 5.14. How often is the word\n",
            "# pizza sampled in each case? Can you think of a faster and\n",
            "# more accurate way to determine how often the word pizza\n",
            "# is sampled?\n",
            "\n",
            "for T in temperatures:\n",
            "    print(f\"temp :{T}\")\n",
            "    scaled_probs = softmax_with_temperature(next_token_logits, T)\n",
            "    print_sampled_tokens(scaled_probs)\n",
            "\n",
            "# more efficient way\n",
            "for T in temperatures:\n",
            "    print(f\"temp :{T}\")\n",
            "    scaled_probs = softmax_with_temperature(next_token_logits, T)\n",
            "    sample = torch.multinomial(scaled_probs, num_samples=1000, replacement=True)#.item()\n",
            "\n",
            "# pizza_sample = torch.sum(sample[])\n",
            "pizza_sample = sum([x.item() for x in sample if x == 6])\n",
            "pizza_sample\n",
            "\n",
            "temp_scaled_probs = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
            "pizza_sample_temp_5 = temp_scaled_probs[2][6]\n",
            "print(pizza_sample_temp_5)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 150,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
                  "Top positions: tensor([3, 7, 0])\n",
                  "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
                  "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
               ]
            }
         ],
         "source": [
            "# topk sampling\n",
            "# selects the top k scores from the logits and masks out the remaining possible token scores by replacing them with -inf \n",
            "# when applying softmax, those scores receive 0 probability and only the top k sampled words are considered for the output/generated token \n",
            "top_k = 3\n",
            "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
            "print(\"Top logits:\", top_logits)\n",
            "print(\"Top positions:\", top_pos)\n",
            "\n",
            "# derive new logits using where condition, by masking all values less than the n=k probability (last element) with -inf\n",
            "new_logits = torch.where(\n",
            "    condition=next_token_logits < top_logits[-1],\n",
            "    input=torch.tensor(float('-inf')),\n",
            "    other=next_token_logits\n",
            ")\n",
            "\n",
            "print(new_logits)\n",
            "# get the probabilitis for the top k logits\n",
            "topk_probas = torch.softmax(new_logits, dim=0)\n",
            "print(topk_probas)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 151,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output text:\n",
                  " Every effort moves you't,\" she's only me, one at have been my by by by\n"
               ]
            }
         ],
         "source": [
            "# combine topk sampling with mulitnomial sampling and temperature scaling to generate text\n",
            "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
            "    for _ in range(max_new_tokens):\n",
            "        idx_cond = idx[:, -context_size:]\n",
            "        with torch.no_grad():\n",
            "            logits = model(idx_cond)\n",
            "        logits = logits[:, -1, :]\n",
            "        if top_k is not None:\n",
            "            top_logits, _ = torch.topk(logits, top_k)\n",
            "        min_val = top_logits[:, -1]\n",
            "        logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device),logits)\n",
            "        if temperature > 0.0:\n",
            "            logits = logits / temperature\n",
            "            probs = torch.softmax(logits, dim=-1)\n",
            "            idx_next = torch.multinomial(probs, num_samples=1)\n",
            "        else:\n",
            "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
            "        if idx_next == eos_id:\n",
            "            break\n",
            "        idx = torch.cat((idx, idx_next), dim=1)\n",
            "    return idx\n",
            "\n",
            "\n",
            "torch.manual_seed(123)\n",
            "token_ids = generate(model=model,\n",
            "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
            "    max_new_tokens=15,\n",
            "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
            "    top_k=25,\n",
            "    temperature=1.4\n",
            ")\n",
            "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 152,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "temp 1, topk 3, text Every effort moves you can he's the with my work too to my--I turned, as\n",
                  "temp 1, topk 10, text Every effort moves you in his painting; and in my painting?\" he was not the room it\n",
                  "temp 1, topk 15, text Every effort moves you was have all the picture't was his was--I my way. And\n",
                  "temp 0.1, topk 3, text Every effort moves you in he of my-rooms, of the with the-. Stroud\n",
                  "temp 0.1, topk 10, text Every effort moves you; he was, that my been he it to have been me out--\n",
                  "temp 0.1, topk 15, text Every effort moves you been denied't; and't a little: the house; and in my\n",
                  "temp 5, topk 3, text Every effort moves you one he was,- I, so,\" he had a note by which\n",
                  "temp 5, topk 10, text Every effort moves you, one of the last dead, all a with your his. I found\n",
                  "temp 5, topk 15, text Every effort moves you know it, on a I can? to were, when; and st\n"
               ]
            }
         ],
         "source": [
            "\n",
            "# exercise 5.2\n",
            "# different topk and temp settings - when is that desired?\n",
            "\n",
            "temps = [1, 0.1, 5]\n",
            "topk = [3, 10, 15]\n",
            "settings_text = []\n",
            "for t in temps:\n",
            "    for k in topk:\n",
            "        settings_text.append({\"temp\": t, \"topk\": k, \"text\": []})\n",
            "# settings_text = [{\"temp\": t, \"topk\": k, \"text\": []} for t, k in zip(temps, topk)]\n",
            "\n",
            "for i, set_ in enumerate(settings_text):\n",
            "    token_ids = generate(model=model,\n",
            "        idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
            "        max_new_tokens=15,\n",
            "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
            "        top_k=25,\n",
            "        temperature=1.4\n",
            "    )\n",
            "    # print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
            "    gen_text = token_ids_to_text(token_ids, tokenizer)\n",
            "    settings_text[i]['text'] = gen_text\n",
            "\n",
            "for set_ in settings_text:\n",
            "    print(f\"temp {set_['temp']}, topk {set_['topk']}, text {set_['text']}\")\n",
            "\n",
            "# EXERCISE 5.3\n",
            "# What are the different combinations of settings for the\n",
            "# generate function to force deterministic behavior, that is,\n",
            "# disabling the random sampling such that it always\n",
            "# produces the same outputs similar to the generate_simple\n",
            "# function?\n",
            "# temp = 1, topk = 1\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 167,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Ep 1 (Step 000000): Train loss 1.852, Val loss 6.204\n",
                  "Ep 1 (Step 000001): Train loss 2.375, Val loss 6.239\n",
                  "Ep 1 (Step 000002): Train loss 1.616, Val loss 6.280\n",
                  "Ep 1 (Step 000003): Train loss 1.173, Val loss 6.288\n",
                  "Ep 1 (Step 000004): Train loss 1.411, Val loss 6.265\n",
                  "Ep 1 (Step 000005): Train loss 1.066, Val loss 6.249\n",
                  "Ep 1 (Step 000006): Train loss 0.929, Val loss 6.250\n",
                  "Ep 1 (Step 000007): Train loss 1.157, Val loss 6.260\n",
                  "Ep 1 (Step 000008): Train loss 1.332, Val loss 6.288\n",
                  "Every effort moves you in the inevitable garlanded frame. Gisburn's the frame. \"There: \" it was, in the women had been to the donkey. \"I had been his pictures--and it was _jardiniere_ full of\n"
               ]
            }
         ],
         "source": [
            "# exercise 5.4 - save and load model weights and continue training for 1 epoch\n",
            "\n",
            "torch.save({\n",
            "    \"model_state_dict\": model.state_dict(),\n",
            "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
            "    },\n",
            "    \"model_and_optimizer_cor_keys.pth\"\n",
            ")\n",
            "\n",
            "checkpoint = torch.load(\"model_and_optimizer_cor_keys.pth\", map_location=device)\n",
            "new_model = GPTModel(GPT_CONFIG_124M)\n",
            "new_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
            "optimizer = torch.optim.AdamW(new_model.parameters(), lr=5e-4, weight_decay=0.1)\n",
            "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
            "# model.train()\n",
            "\n",
            "num_epochs = 1\n",
            "train_losses, val_losses, tokens_seen = train_model_simple(\n",
            "    new_model, train_loader, val_loader, optimizer, device,\n",
            "    num_epochs=num_epochs, eval_freq=1, eval_iter=1,\n",
            "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
            ")\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 154,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "('gpt_download.py', <http.client.HTTPMessage at 0x7221e1e40>)"
                  ]
               },
               "execution_count": 154,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import urllib.request\n",
            "url = (\n",
            "\"https://raw.githubusercontent.com/rasbt/\"\n",
            "\"LLMs-from-scratch/main/ch05/\"\n",
            "\"01_main-chapter-code/gpt_download.py\"\n",
            ")\n",
            "filename = url.split('/')[-1]\n",
            "urllib.request.urlretrieve(url, filename)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 155,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
                  "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
                  "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
                  "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
                  "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
                  "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
                  "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
               ]
            }
         ],
         "source": [
            "from gpt_download import download_and_load_gpt2\n",
            "settings, params = download_and_load_gpt2(\n",
            "model_size=\"124M\", models_dir=\"gpt2\"\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 156,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
                  "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
                  "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
                  "   0.04531523]\n",
                  " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
                  "   0.04318958]\n",
                  " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
                  "  -0.08785918]\n",
                  " ...\n",
                  " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
                  "  -0.06952604]\n",
                  " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
                  "  -0.02245961]\n",
                  " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
                  "   0.12067825]]\n",
                  "Token embedding weight tensor dimensions: (50257, 768)\n"
               ]
            }
         ],
         "source": [
            "print(\"Settings:\", settings)\n",
            "print(\"Parameter dictionary keys:\", params.keys())\n",
            "\n",
            "print(params[\"wte\"])\n",
            "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 168,
         "metadata": {},
         "outputs": [],
         "source": [
            "model_configs = {\n",
            "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
            "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
            "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
            "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
            "}\n",
            "\n",
            "model_name = \"gpt2-small (124M)\"\n",
            "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
            "NEW_CONFIG.update(model_configs[model_name])\n",
            "\n",
            "NEW_CONFIG.update({\"context_length\": 1024})\n",
            "NEW_CONFIG.update({\"qkv_bias\": True})\n",
            "\n",
            "gpt = GPTModel(NEW_CONFIG)\n",
            "gpt.eval()\n",
            "\n",
            "def assign(left, right):\n",
            "    if left.shape != right.shape:\n",
            "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
            "    \"Right: {right.shape}\"\n",
            "    )\n",
            "    return torch.nn.Parameter(torch.tensor(right))\n",
            "\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 170,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np\n",
            "\n",
            "def load_weights_into_gpt(gpt, params):\n",
            "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
            "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
            "    for b in range(len(params[\"blocks\"])):\n",
            "        q_w, k_w, v_w = np.split(\n",
            "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
            "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
            "        gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
            "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
            "        gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
            "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
            "        gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
            "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
            "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
            "        gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
            "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
            "        gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
            "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
            "        gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
            "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
            "        gpt.trf_blocks[b].att.out_proj.weight,\n",
            "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
            "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
            "        gpt.trf_blocks[b].att.out_proj.bias,\n",
            "        params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
            "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
            "        gpt.trf_blocks[b].ff.layers[0].weight,\n",
            "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
            "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
            "        gpt.trf_blocks[b].ff.layers[0].bias,\n",
            "        params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
            "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
            "        gpt.trf_blocks[b].ff.layers[2].weight,\n",
            "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
            "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
            "        gpt.trf_blocks[b].ff.layers[2].bias,\n",
            "        params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
            "        gpt.trf_blocks[b].norm1.scale = assign(\n",
            "        gpt.trf_blocks[b].norm1.scale,\n",
            "        params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
            "        gpt.trf_blocks[b].norm1.shift = assign(\n",
            "        gpt.trf_blocks[b].norm1.shift,\n",
            "        params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
            "        gpt.trf_blocks[b].norm2.scale = assign(\n",
            "        gpt.trf_blocks[b].norm2.scale,\n",
            "        params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
            "        gpt.trf_blocks[b].norm2.shift = assign(\n",
            "        gpt.trf_blocks[b].norm2.shift,\n",
            "        params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
            "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
            "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
            "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
            "\n",
            "load_weights_into_gpt(gpt, params)\n",
            "gpt.to(device);"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 173,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output text:\n",
                  " Every effort moves you're with an act this. You may only at least or lack of here, he's on, 17 hours gone way of\n"
               ]
            }
         ],
         "source": [
            "torch.manual_seed(123)\n",
            "\n",
            "token_ids = generate(\n",
            "    model=gpt,\n",
            "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
            "    max_new_tokens=25,\n",
            "    context_size=NEW_CONFIG[\"context_length\"],\n",
            "    top_k=50,\n",
            "    temperature=1.5\n",
            ")\n",
            "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 161,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Training loss: 8.154706372155083\n",
                  "Validation loss: 7.950900077819824\n"
               ]
            }
         ],
         "source": [
            "\n",
            "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
            "train_loss = calc_loss_loader(train_loader, gpt, device)\n",
            "val_loss = calc_loss_loader(val_loader, gpt, device)\n",
            "\n",
            "print(\"Training loss:\", train_loss)\n",
            "print(\"Validation loss:\", val_loss)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 162,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Ep 1 (Step 000000): Train loss 8.195, Val loss 7.951\n",
                  "Ep 1 (Step 000005): Train loss 8.194, Val loss 7.951\n",
                  "Every effort moves you are the Jungle, I to the smell like a man's the year after the great, if the next was a new year to the most likely to be a step by the new, of the U. It's of theodora is to-\n",
                  "Ep 2 (Step 000010): Train loss 8.303, Val loss 7.951\n",
                  "Ep 2 (Step 000015): Train loss 8.021, Val loss 7.951\n",
                  "Every effort moves you are the Jungle, I to the smell like a man's the year after the great, if the next was a new year to the most likely to be a step by the new, of the U. It's of theodora is to-\n",
                  "Ep 3 (Step 000020): Train loss 8.146, Val loss 7.951\n",
                  "Ep 3 (Step 000025): Train loss 8.164, Val loss 7.951\n",
                  "Every effort moves you are the Jungle, I to the smell like a man's the year after the great, if the next was a new year to the most likely to be a step by the new, of the U. It's of theodora is to-\n",
                  "Ep 4 (Step 000030): Train loss 8.168, Val loss 7.951\n",
                  "Ep 4 (Step 000035): Train loss 8.235, Val loss 7.951\n",
                  "Every effort moves you are the Jungle, I to the smell like a man's the year after the great, if the next was a new year to the most likely to be a step by the new, of the U. It's of theodora is to-\n",
                  "Ep 5 (Step 000040): Train loss 8.023, Val loss 7.951\n",
                  "Every effort moves you are the Jungle, I to the smell like a man's the year after the great, if the next was a new year to the most likely to be a step by the new, of the U. It's of theodora is to-\n"
               ]
            }
         ],
         "source": [
            "# exercise 5.5 \n",
            "# calculate training and val losses with pretrained openai weights\n",
            "\n",
            "\n",
            "num_epochs = 5\n",
            "train_losses, val_losses, tokens_seen = train_model_simple(\n",
            "    gpt, train_loader, val_loader, optimizer, device,\n",
            "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
            "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 163,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 500x300 with 2 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
            "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "stanford",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.16"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
